Transparency is an important principle of AI governance. Where members of the public interact directly with SE systems that use AI technology, the use of such AI technology should be disclosed by the SE. 6

## **4.5 AI Risk Assessment and Management**

The SE must perform a Risk Assessment for each AI system that meets the criteria set forth in Section 3.2. The Risk Assessment should include a review of all security, privacy, legal, reputational, and competency risks as well as the additional risks listed in this policy. SEs should adopt applicable elements of the current version of the National Institute of Standards and Technology (NIST) AI 100-1 Artificial Intelligence Risk Management Framework (RMF) and accompanying NIST Artificial Intelligence Risk Management Framework Playbook to address and meet the characteristics of trustworthy AI. 7

In addition to the use of the NIST AI 100-1 AI RMF and Playbook, SEs must perform the Risk Assessment following the requirements set forth in NYS-S14-001: Information Security Risk Management. SEs should also refer to the NYS-S14-002: Information Classification Standard for guidance on how to rate risks for an AI Risk Assessment.

## **4.6 AI Inventory**

ITS shall create and maintain an inventory that identifies AI systems in use and in scope under this policy.

ITS shall make such an inventory publicly available to the extent practicable and will separately issue guidance to SEs on the manner and composition of information to be furnished to ITS under this section. SEs will submit new and existing AI systems that meet the requirements of the guidance within 180 days of the issuance of the guidance.

## **4.7 Privacy**

SEs should develop polices and controls to ensure the appropriate use of AI systems, particularly when the SE identifies a need to use the AI system to process personally identifiable, confidential, or sensitive information. Examples may include:

Â· A privacy impact assessment;