{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06bb24d2-f2f7-455f-8854-6d1ae1f233b8",
   "metadata": {},
   "source": [
    "# Evaluating the fine tuned model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8308b229-b520-4e82-a783-eb921bb955e7",
   "metadata": {},
   "source": [
    "### Needed packages and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91e41b41-f60a-4b0f-91a1-cd273b60f21b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T16:06:00.716772Z",
     "start_time": "2024-11-11T16:05:57.936808Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting docling[tesserocr]~=2.8.3 (from -r requirements.txt (line 1))\n",
      "  Obtaining dependency information for docling[tesserocr]~=2.8.3 from https://files.pythonhosted.org/packages/02/e9/8d81e497365224e2ea80ce0b625f1e9339d736a8a7f7c2224c6f56be3131/docling-2.8.3-py3-none-any.whl.metadata\n",
      "  Downloading docling-2.8.3-py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting einops==0.8.0 (from -r requirements.txt (line 2))\n",
      "  Obtaining dependency information for einops==0.8.0 from https://files.pythonhosted.org/packages/44/5a/f0b9ad6c0a9017e62d4735daaeb11ba3b6c009d69a26141b258cd37b5588/einops-0.8.0-py3-none-any.whl.metadata\n",
      "  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting langchain==0.3.11 (from -r requirements.txt (line 3))\n",
      "  Obtaining dependency information for langchain==0.3.11 from https://files.pythonhosted.org/packages/ba/4a/26620afcff880f6058756786d9b858d348ac29c815e44f57b6c2c07bf86d/langchain-0.3.11-py3-none-any.whl.metadata\n",
      "  Downloading langchain-0.3.11-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting langchain-community==0.3.11 (from -r requirements.txt (line 4))\n",
      "  Obtaining dependency information for langchain-community==0.3.11 from https://files.pythonhosted.org/packages/dc/c2/aeb43e7f879d429df40f742228dba747d790655f3eb0e2082b7d9854f0fd/langchain_community-0.3.11-py3-none-any.whl.metadata\n",
      "  Downloading langchain_community-0.3.11-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting langchain-openai==0.2.12 (from -r requirements.txt (line 5))\n",
      "  Obtaining dependency information for langchain-openai==0.2.12 from https://files.pythonhosted.org/packages/cd/01/7a0259929474c47cadecaef64fd9361a95c8091d5f88d53c54d251abf05f/langchain_openai-0.2.12-py3-none-any.whl.metadata\n",
      "  Downloading langchain_openai-0.2.12-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting langchain-milvus==0.1.7 (from -r requirements.txt (line 6))\n",
      "  Obtaining dependency information for langchain-milvus==0.1.7 from https://files.pythonhosted.org/packages/e0/f1/7138884f3d691d5a4c79a026f9136a2eed146ee98fea46e3fe3a03c91259/langchain_milvus-0.1.7-py3-none-any.whl.metadata\n",
      "  Downloading langchain_milvus-0.1.7-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langchain-text-splitters==0.3.2 (from -r requirements.txt (line 7))\n",
      "  Obtaining dependency information for langchain-text-splitters==0.3.2 from https://files.pythonhosted.org/packages/ee/c6/5ba25c8bad647e92a92b3066177ab10d78efbd16c0b9919948cdcd18b027/langchain_text_splitters-0.3.2-py3-none-any.whl.metadata\n",
      "  Downloading langchain_text_splitters-0.3.2-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting openai==1.57.3 (from -r requirements.txt (line 8))\n",
      "  Obtaining dependency information for openai==1.57.3 from https://files.pythonhosted.org/packages/8c/14/e33e944fcf03c79cde60ad0677dc4f1bc13b4a1ef7fcbf1961b8d13a568c/openai-1.57.3-py3-none-any.whl.metadata\n",
      "  Downloading openai-1.57.3-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting pymilvus==2.5.0 (from -r requirements.txt (line 9))\n",
      "  Obtaining dependency information for pymilvus==2.5.0 from https://files.pythonhosted.org/packages/01/f1/76af6c8e1481879f5e0c0d885ab899ab8869fd939b27ac7a0b6c3b3b4ebe/pymilvus-2.5.0-py3-none-any.whl.metadata\n",
      "  Downloading pymilvus-2.5.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting python-dotenv==1.0.1 (from -r requirements.txt (line 10))\n",
      "  Obtaining dependency information for python-dotenv==1.0.1 from https://files.pythonhosted.org/packages/6a/3e/b68c118422ec867fa7ab88444e1274aa40681c606d59ac27de5a5588f082/python_dotenv-1.0.1-py3-none-any.whl.metadata\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting sentence-transformers==3.3.1 (from -r requirements.txt (line 11))\n",
      "  Obtaining dependency information for sentence-transformers==3.3.1 from https://files.pythonhosted.org/packages/8b/c8/990e22a465e4771338da434d799578865d6d7ef1fdb50bd844b7ecdcfa19/sentence_transformers-3.3.1-py3-none-any.whl.metadata\n",
      "  Downloading sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting torch (from -r requirements.txt (line 12))\n",
      "  Obtaining dependency information for torch from https://files.pythonhosted.org/packages/d1/35/e8b2daf02ce933e4518e6f5682c72fd0ed66c15910ea1fb4168f442b71c4/torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl.metadata\n",
      "  Downloading torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Collecting torchvision (from -r requirements.txt (line 13))\n",
      "  Obtaining dependency information for torchvision from https://files.pythonhosted.org/packages/de/e9/e190ecec448d5a2abad8348cf085fcb39962a491e3f40dcb023721e04feb/torchvision-0.20.1-cp311-cp311-manylinux1_x86_64.whl.metadata\n",
      "  Downloading torchvision-0.20.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
      "Collecting ragas==0.2.8 (from -r requirements.txt (line 14))\n",
      "  Obtaining dependency information for ragas==0.2.8 from https://files.pythonhosted.org/packages/47/0a/a1c20b2dd5b00544718777b58cc478a46b8ac95675e90330ee4fe01ac188/ragas-0.2.8-py3-none-any.whl.metadata\n",
      "  Downloading ragas-0.2.8-py3-none-any.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/app-root/lib64/python3.11/site-packages (from langchain==0.3.11->-r requirements.txt (line 3)) (6.0.2)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain==0.3.11->-r requirements.txt (line 3))\n",
      "  Obtaining dependency information for SQLAlchemy<3,>=1.4 from https://files.pythonhosted.org/packages/b4/5f/95e0ed74093ac3c0db6acfa944d4d8ac6284ef5e1136b878a327ea1f975a/SQLAlchemy-2.0.36-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading SQLAlchemy-2.0.36-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/app-root/lib64/python3.11/site-packages (from langchain==0.3.11->-r requirements.txt (line 3)) (3.10.10)\n",
      "Collecting langchain-core<0.4.0,>=0.3.24 (from langchain==0.3.11->-r requirements.txt (line 3))\n",
      "  Obtaining dependency information for langchain-core<0.4.0,>=0.3.24 from https://files.pythonhosted.org/packages/a8/eb/b5681dfa46a8f994d2b8d23610d8545ff80c6ad3fe6cabf76cea3256a8ea/langchain_core-0.3.24-py3-none-any.whl.metadata\n",
      "  Downloading langchain_core-0.3.24-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting langsmith<0.3,>=0.1.17 (from langchain==0.3.11->-r requirements.txt (line 3))\n",
      "  Obtaining dependency information for langsmith<0.3,>=0.1.17 from https://files.pythonhosted.org/packages/a1/f0/9040d7adff12c3d4bebedb561aed3235b76d04051aee1f267124ef061a53/langsmith-0.2.3-py3-none-any.whl.metadata\n",
      "  Downloading langsmith-0.2.3-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting numpy<2,>=1.22.4 (from langchain==0.3.11->-r requirements.txt (line 3))\n",
      "  Obtaining dependency information for numpy<2,>=1.22.4 from https://files.pythonhosted.org/packages/3a/d0/edc009c27b406c4f9cbc79274d6e46d634d139075492ad055e3d68445925/numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pydantic<3.0.0,>=2.7.4 (from langchain==0.3.11->-r requirements.txt (line 3))\n",
      "  Obtaining dependency information for pydantic<3.0.0,>=2.7.4 from https://files.pythonhosted.org/packages/62/51/72c18c55cf2f46ff4f91ebcc8f75aa30f7305f3d726be3f4ebffb4ae972b/pydantic-2.10.3-py3-none-any.whl.metadata\n",
      "  Downloading pydantic-2.10.3-py3-none-any.whl.metadata (172 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.0/172.0 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2 in /opt/app-root/lib64/python3.11/site-packages (from langchain==0.3.11->-r requirements.txt (line 3)) (2.32.3)\n",
      "Collecting tenacity!=8.4.0,<10,>=8.1.0 (from langchain==0.3.11->-r requirements.txt (line 3))\n",
      "  Obtaining dependency information for tenacity!=8.4.0,<10,>=8.1.0 from https://files.pythonhosted.org/packages/b6/cb/b86984bed139586d01532a587464b5805f12e397594f19f931c4c2fbfa61/tenacity-9.0.0-py3-none-any.whl.metadata\n",
      "  Downloading tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community==0.3.11->-r requirements.txt (line 4))\n",
      "  Obtaining dependency information for dataclasses-json<0.7,>=0.5.7 from https://files.pythonhosted.org/packages/c3/be/d0d44e092656fe7a06b55e6103cbce807cdbdee17884a5367c68c9860853/dataclasses_json-0.6.7-py3-none-any.whl.metadata\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community==0.3.11->-r requirements.txt (line 4))\n",
      "  Obtaining dependency information for httpx-sse<0.5.0,>=0.4.0 from https://files.pythonhosted.org/packages/e1/9b/a181f281f65d776426002f330c31849b86b31fc9d848db62e16f03ff739f/httpx_sse-0.4.0-py3-none-any.whl.metadata\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community==0.3.11->-r requirements.txt (line 4))\n",
      "  Obtaining dependency information for pydantic-settings<3.0.0,>=2.4.0 from https://files.pythonhosted.org/packages/5e/f9/ff95fd7d760af42f647ea87f9b8a383d891cdb5e5dbd4613edaeb094252a/pydantic_settings-2.6.1-py3-none-any.whl.metadata\n",
      "  Downloading pydantic_settings-2.6.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai==0.2.12->-r requirements.txt (line 5))\n",
      "  Obtaining dependency information for tiktoken<1,>=0.7 from https://files.pythonhosted.org/packages/01/c4/c4a4360de845217b6aa9709c15773484b50479f36bb50419c443204e5de9/tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/app-root/lib64/python3.11/site-packages (from openai==1.57.3->-r requirements.txt (line 8)) (4.6.2.post1)\n",
      "Collecting distro<2,>=1.7.0 (from openai==1.57.3->-r requirements.txt (line 8))\n",
      "  Obtaining dependency information for distro<2,>=1.7.0 from https://files.pythonhosted.org/packages/12/b3/231ffd4ab1fc9d679809f356cebee130ac7daa00d6d6f3206dd4fd137e9e/distro-1.9.0-py3-none-any.whl.metadata\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/app-root/lib64/python3.11/site-packages (from openai==1.57.3->-r requirements.txt (line 8)) (0.27.2)\n",
      "Collecting jiter<1,>=0.4.0 (from openai==1.57.3->-r requirements.txt (line 8))\n",
      "  Obtaining dependency information for jiter<1,>=0.4.0 from https://files.pythonhosted.org/packages/f8/9b/92f9da9a9e107d019bcf883cd9125fa1690079f323f5a9d5c6986eeec3c0/jiter-0.8.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading jiter-0.8.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: sniffio in /opt/app-root/lib64/python3.11/site-packages (from openai==1.57.3->-r requirements.txt (line 8)) (1.3.1)\n",
      "Collecting tqdm>4 (from openai==1.57.3->-r requirements.txt (line 8))\n",
      "  Obtaining dependency information for tqdm>4 from https://files.pythonhosted.org/packages/d0/30/dc54f88dd4a2b5dc8a0279bdd7270e735851848b762aeb1c1184ed1f6b14/tqdm-4.67.1-py3-none-any.whl.metadata\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m259.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions<5,>=4.11 in /opt/app-root/lib64/python3.11/site-packages (from openai==1.57.3->-r requirements.txt (line 8)) (4.12.2)\n",
      "Requirement already satisfied: setuptools>69 in /opt/app-root/lib64/python3.11/site-packages (from pymilvus==2.5.0->-r requirements.txt (line 9)) (74.1.3)\n",
      "Collecting grpcio<=1.67.1,>=1.49.1 (from pymilvus==2.5.0->-r requirements.txt (line 9))\n",
      "  Obtaining dependency information for grpcio<=1.67.1,>=1.49.1 from https://files.pythonhosted.org/packages/f7/1e/0011408ebabf9bd69f4f87cc1515cbfe2094e5a32316f8714a75fd8ddfcb/grpcio-1.67.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading grpcio-1.67.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
      "Collecting protobuf>=3.20.0 (from pymilvus==2.5.0->-r requirements.txt (line 9))\n",
      "  Obtaining dependency information for protobuf>=3.20.0 from https://files.pythonhosted.org/packages/04/52/c97c58a33b3d6c89a8138788576d372a90a6556f354799971c6b4d16d871/protobuf-5.29.1-cp38-abi3-manylinux2014_x86_64.whl.metadata\n",
      "  Downloading protobuf-5.29.1-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Collecting ujson>=2.0.0 (from pymilvus==2.5.0->-r requirements.txt (line 9))\n",
      "  Obtaining dependency information for ujson>=2.0.0 from https://files.pythonhosted.org/packages/29/45/f5f5667427c1ec3383478092a414063ddd0dfbebbcc533538fe37068a0a3/ujson-5.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading ujson-5.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n",
      "Collecting pandas>=1.2.4 (from pymilvus==2.5.0->-r requirements.txt (line 9))\n",
      "  Obtaining dependency information for pandas>=1.2.4 from https://files.pythonhosted.org/packages/cd/5f/4dba1d39bb9c38d574a9a22548c540177f78ea47b32f99c0ff2ec499fac5/pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m261.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting milvus-lite>=2.4.0 (from pymilvus==2.5.0->-r requirements.txt (line 9))\n",
      "  Obtaining dependency information for milvus-lite>=2.4.0 from https://files.pythonhosted.org/packages/84/65/639cb552c892ba5fef73301f878b2e7cabb59c918e0c49c9cf3026d49447/milvus_lite-2.4.10-py3-none-manylinux2014_x86_64.whl.metadata\n",
      "  Downloading milvus_lite-2.4.10-py3-none-manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers==3.3.1->-r requirements.txt (line 11))\n",
      "  Obtaining dependency information for transformers<5.0.0,>=4.41.0 from https://files.pythonhosted.org/packages/d0/a7/7eedcf6a359e1e1eff3bc204ad022485aa5d88c08e1e3e0e0aee8a2e2235/transformers-4.47.0-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.47.0-py3-none-any.whl.metadata (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m200.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting scikit-learn (from sentence-transformers==3.3.1->-r requirements.txt (line 11))\n",
      "  Obtaining dependency information for scikit-learn from https://files.pythonhosted.org/packages/0e/ec/1b15b59c6cc7a993320a52234369e787f50345a4753e50d5a015a91e1a20/scikit_learn-1.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading scikit_learn-1.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting scipy (from sentence-transformers==3.3.1->-r requirements.txt (line 11))\n",
      "  Obtaining dependency information for scipy from https://files.pythonhosted.org/packages/93/6b/701776d4bd6bdd9b629c387b5140f006185bd8ddea16788a44434376b98f/scipy-1.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading scipy-1.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m288.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub>=0.20.0 (from sentence-transformers==3.3.1->-r requirements.txt (line 11))\n",
      "  Obtaining dependency information for huggingface-hub>=0.20.0 from https://files.pythonhosted.org/packages/44/5a/dc6af87c61f89b23439eb95521e4e99862636cfd538ae12fd36be5483e5f/huggingface_hub-0.26.5-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.26.5-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting Pillow (from sentence-transformers==3.3.1->-r requirements.txt (line 11))\n",
      "  Obtaining dependency information for Pillow from https://files.pythonhosted.org/packages/39/63/b3fc299528d7df1f678b0666002b37affe6b8751225c3d9c12cf530e73ed/pillow-11.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata\n",
      "  Downloading pillow-11.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
      "Collecting datasets (from ragas==0.2.8->-r requirements.txt (line 14))\n",
      "  Obtaining dependency information for datasets from https://files.pythonhosted.org/packages/d7/84/0df6c5981f5fc722381662ff8cfbdf8aad64bec875f75d80b55bfef394ce/datasets-3.2.0-py3-none-any.whl.metadata\n",
      "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: nest-asyncio in /opt/app-root/lib64/python3.11/site-packages (from ragas==0.2.8->-r requirements.txt (line 14)) (1.6.0)\n",
      "Collecting appdirs (from ragas==0.2.8->-r requirements.txt (line 14))\n",
      "  Obtaining dependency information for appdirs from https://files.pythonhosted.org/packages/3b/00/2344469e2084fb287c2e0b57b72910309874c3245463acd6cf5e3db69324/appdirs-1.4.4-py2.py3-none-any.whl.metadata\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting pysbd>=0.3.4 (from ragas==0.2.8->-r requirements.txt (line 14))\n",
      "  Obtaining dependency information for pysbd>=0.3.4 from https://files.pythonhosted.org/packages/48/0a/c99fb7d7e176f8b176ef19704a32e6a9c6aafdf19ef75a187f701fc15801/pysbd-0.3.4-py3-none-any.whl.metadata\n",
      "  Downloading pysbd-0.3.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /opt/app-root/lib64/python3.11/site-packages (from docling[tesserocr]~=2.8.3->-r requirements.txt (line 1)) (4.12.3)\n",
      "Requirement already satisfied: certifi>=2024.7.4 in /opt/app-root/lib64/python3.11/site-packages (from docling[tesserocr]~=2.8.3->-r requirements.txt (line 1)) (2024.8.30)\n",
      "Collecting deepsearch-glm<0.27.0,>=0.26.1 (from docling[tesserocr]~=2.8.3->-r requirements.txt (line 1))\n",
      "  Obtaining dependency information for deepsearch-glm<0.27.0,>=0.26.1 from https://files.pythonhosted.org/packages/78/0b/9aeacd70e51ad5288cb75d3e2f02c859ff628934e119f70c4389f3c671dd/deepsearch_glm-0.26.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading deepsearch_glm-0.26.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting docling-core<3.0.0,>=2.6.1 (from docling[tesserocr]~=2.8.3->-r requirements.txt (line 1))\n",
      "  Obtaining dependency information for docling-core<3.0.0,>=2.6.1 from https://files.pythonhosted.org/packages/c8/58/677550bdba8eb9da78bb850ba9b38da35dd329c2608ad03957766e57062d/docling_core-2.9.0-py3-none-any.whl.metadata\n",
      "  Downloading docling_core-2.9.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting docling-ibm-models<3.0.0,>=2.0.6 (from docling[tesserocr]~=2.8.3->-r requirements.txt (line 1))\n",
      "  Obtaining dependency information for docling-ibm-models<3.0.0,>=2.0.6 from https://files.pythonhosted.org/packages/48/81/15cdac0f6d58eb3ced9c53e161d91586e880fee85f264fc6d35b9fea4c4b/docling_ibm_models-2.0.8-py3-none-any.whl.metadata\n",
      "  Downloading docling_ibm_models-2.0.8-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting docling-parse<3.0.0,>=2.0.5 (from docling[tesserocr]~=2.8.3->-r requirements.txt (line 1))\n",
      "  Obtaining dependency information for docling-parse<3.0.0,>=2.0.5 from https://files.pythonhosted.org/packages/1d/86/ca1c98c7c67f0c0e46a951960948bdca673734a4ee9dec6ef6a265a7f2b2/docling_parse-2.1.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading docling_parse-2.1.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
      "Collecting easyocr<2.0,>=1.7 (from docling[tesserocr]~=2.8.3->-r requirements.txt (line 1))\n",
      "  Obtaining dependency information for easyocr<2.0,>=1.7 from https://files.pythonhosted.org/packages/bb/84/4a2cab0e6adde6a85e7ba543862e5fc0250c51f3ac721a078a55cdcff250/easyocr-1.7.2-py3-none-any.whl.metadata\n",
      "  Downloading easyocr-1.7.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting filetype<2.0.0,>=1.2.0 (from docling[tesserocr]~=2.8.3->-r requirements.txt (line 1))\n",
      "  Obtaining dependency information for filetype<2.0.0,>=1.2.0 from https://files.pythonhosted.org/packages/18/79/1b8fa1bb3568781e84c9200f951c735f3f157429f44be0495da55894d620/filetype-1.2.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting lxml<6.0.0,>=4.0.0 (from docling[tesserocr]~=2.8.3->-r requirements.txt (line 1))\n",
      "  Obtaining dependency information for lxml<6.0.0,>=4.0.0 from https://files.pythonhosted.org/packages/42/07/b29571a58a3a80681722ea8ed0ba569211d9bb8531ad49b5cacf6d409185/lxml-5.3.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata\n",
      "  Downloading lxml-5.3.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting marko<3.0.0,>=2.1.2 (from docling[tesserocr]~=2.8.3->-r requirements.txt (line 1))\n",
      "  Obtaining dependency information for marko<3.0.0,>=2.1.2 from https://files.pythonhosted.org/packages/ef/9b/3dbfbe6ee255b1c37a37e2a6046adb2e77763a020591dae63e5005a2c8d7/marko-2.1.2-py3-none-any.whl.metadata\n",
      "  Downloading marko-2.1.2-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting openpyxl<4.0.0,>=3.1.5 (from docling[tesserocr]~=2.8.3->-r requirements.txt (line 1))\n",
      "  Obtaining dependency information for openpyxl<4.0.0,>=3.1.5 from https://files.pythonhosted.org/packages/c0/da/977ded879c29cbd04de313843e76868e6e13408a94ed6b987245dc7c8506/openpyxl-3.1.5-py2.py3-none-any.whl.metadata\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain==0.3.11->-r requirements.txt (line 3))\n",
      "  Obtaining dependency information for pydantic<3.0.0,>=2.7.4 from https://files.pythonhosted.org/packages/df/e4/ba44652d562cbf0bf320e0f3810206149c8a4e99cdbf66da82e97ab53a15/pydantic-2.9.2-py3-none-any.whl.metadata\n",
      "  Downloading pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.4/149.4 kB\u001b[0m \u001b[31m307.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pypdfium2<5.0.0,>=4.30.0 (from docling[tesserocr]~=2.8.3->-r requirements.txt (line 1))\n",
      "  Obtaining dependency information for pypdfium2<5.0.0,>=4.30.0 from https://files.pythonhosted.org/packages/65/cd/3f1edf20a0ef4a212a5e20a5900e64942c5a374473671ac0780eaa08ea80/pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m255.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting python-docx<2.0.0,>=1.1.2 (from docling[tesserocr]~=2.8.3->-r requirements.txt (line 1))\n",
      "  Obtaining dependency information for python-docx<2.0.0,>=1.1.2 from https://files.pythonhosted.org/packages/3e/3d/330d9efbdb816d3f60bf2ad92f05e1708e4a1b9abe80461ac3444c83f749/python_docx-1.1.2-py3-none-any.whl.metadata\n",
      "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting python-pptx<2.0.0,>=1.0.2 (from docling[tesserocr]~=2.8.3->-r requirements.txt (line 1))\n",
      "  Obtaining dependency information for python-pptx<2.0.0,>=1.0.2 from https://files.pythonhosted.org/packages/d9/4f/00be2196329ebbff56ce564aa94efb0fbc828d00de250b1980de1a34ab49/python_pptx-1.0.2-py3-none-any.whl.metadata\n",
      "  Downloading python_pptx-1.0.2-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting rtree<2.0.0,>=1.3.0 (from docling[tesserocr]~=2.8.3->-r requirements.txt (line 1))\n",
      "  Obtaining dependency information for rtree<2.0.0,>=1.3.0 from https://files.pythonhosted.org/packages/70/db/6c8bc20061572c33766ade296071d0127e7365d4d3ff54a6c2c075de637b/Rtree-1.3.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata\n",
      "  Downloading Rtree-1.3.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting tesserocr<3.0.0,>=2.7.1 (from docling[tesserocr]~=2.8.3->-r requirements.txt (line 1))\n",
      "  Obtaining dependency information for tesserocr<3.0.0,>=2.7.1 from https://files.pythonhosted.org/packages/21/80/93ff9fc65d76d1ede7fb21454959568fe354e905d8f8dd26d46190c42700/tesserocr-2.7.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata\n",
      "  Downloading tesserocr-2.7.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
      "Collecting typer<0.13.0,>=0.12.5 (from docling[tesserocr]~=2.8.3->-r requirements.txt (line 1))\n",
      "  Obtaining dependency information for typer<0.13.0,>=0.12.5 from https://files.pythonhosted.org/packages/a8/2b/886d13e742e514f704c33c4caa7df0f3b89e5a25ef8db02aa9ca3d9535d5/typer-0.12.5-py3-none-any.whl.metadata\n",
      "  Downloading typer-0.12.5-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting filelock (from torch->-r requirements.txt (line 12))\n",
      "  Obtaining dependency information for filelock from https://files.pythonhosted.org/packages/b9/f8/feced7779d755758a52d1f6635d990b8d98dc0a29fa568bbe0625f18fdf3/filelock-3.16.1-py3-none-any.whl.metadata\n",
      "  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting networkx (from torch->-r requirements.txt (line 12))\n",
      "  Obtaining dependency information for networkx from https://files.pythonhosted.org/packages/b9/54/dd730b32ea14ea797530a4479b2ed46a6fb250f682a9cfb997e968bf0261/networkx-3.4.2-py3-none-any.whl.metadata\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in /opt/app-root/lib64/python3.11/site-packages (from torch->-r requirements.txt (line 12)) (3.1.4)\n",
      "Collecting fsspec (from torch->-r requirements.txt (line 12))\n",
      "  Obtaining dependency information for fsspec from https://files.pythonhosted.org/packages/c6/b2/454d6e7f0158951d8a78c2e1eb4f69ae81beb8dca5fee9809c6c99e9d0d0/fsspec-2024.10.0-py3-none-any.whl.metadata\n",
      "  Downloading fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->-r requirements.txt (line 12))\n",
      "  Obtaining dependency information for nvidia-cuda-nvrtc-cu12==12.4.127 from https://files.pythonhosted.org/packages/2c/14/91ae57cd4db3f9ef7aa99f4019cfa8d54cb4caa7e00975df6467e9725a9f/nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->-r requirements.txt (line 12))\n",
      "  Obtaining dependency information for nvidia-cuda-runtime-cu12==12.4.127 from https://files.pythonhosted.org/packages/ea/27/1795d86fe88ef397885f2e580ac37628ed058a92ed2c39dc8eac3adf0619/nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->-r requirements.txt (line 12))\n",
      "  Obtaining dependency information for nvidia-cuda-cupti-cu12==12.4.127 from https://files.pythonhosted.org/packages/67/42/f4f60238e8194a3106d06a058d494b18e006c10bb2b915655bd9f6ea4cb1/nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->-r requirements.txt (line 12))\n",
      "  Obtaining dependency information for nvidia-cudnn-cu12==9.1.0.70 from https://files.pythonhosted.org/packages/9f/fd/713452cd72343f682b1c7b9321e23829f00b842ceaedcda96e742ea0b0b3/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->-r requirements.txt (line 12))\n",
      "  Obtaining dependency information for nvidia-cublas-cu12==12.4.5.8 from https://files.pythonhosted.org/packages/ae/71/1c91302526c45ab494c23f61c7a84aa568b8c1f9d196efa5993957faf906/nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->-r requirements.txt (line 12))\n",
      "  Obtaining dependency information for nvidia-cufft-cu12==11.2.1.3 from https://files.pythonhosted.org/packages/27/94/3266821f65b92b3138631e9c8e7fe1fb513804ac934485a8d05776e1dd43/nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->-r requirements.txt (line 12))\n",
      "  Obtaining dependency information for nvidia-curand-cu12==10.3.5.147 from https://files.pythonhosted.org/packages/8a/6d/44ad094874c6f1b9c654f8ed939590bdc408349f137f9b98a3a23ccec411/nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->-r requirements.txt (line 12))\n",
      "  Obtaining dependency information for nvidia-cusolver-cu12==11.6.1.9 from https://files.pythonhosted.org/packages/3a/e1/5b9089a4b2a4790dfdea8b3a006052cfecff58139d5a4e34cb1a51df8d6f/nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->-r requirements.txt (line 12))\n",
      "  Obtaining dependency information for nvidia-cusparse-cu12==12.3.1.170 from https://files.pythonhosted.org/packages/db/f7/97a9ea26ed4bbbfc2d470994b8b4f338ef663be97b8f677519ac195e113d/nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch->-r requirements.txt (line 12))\n",
      "  Obtaining dependency information for nvidia-nccl-cu12==2.21.5 from https://files.pythonhosted.org/packages/df/99/12cd266d6233f47d00daf3a72739872bdc10267d0383508b0b9c84a18bb6/nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata\n",
      "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch->-r requirements.txt (line 12))\n",
      "  Obtaining dependency information for nvidia-nvtx-cu12==12.4.127 from https://files.pythonhosted.org/packages/87/20/199b8713428322a2f22b722c62b8cc278cc53dffa9705d744484b5035ee9/nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata\n",
      "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->-r requirements.txt (line 12))\n",
      "  Obtaining dependency information for nvidia-nvjitlink-cu12==12.4.127 from https://files.pythonhosted.org/packages/ff/ff/847841bacfbefc97a00036e0fce5a0f086b640756dc38caea5e1bb002655/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.1.0 (from torch->-r requirements.txt (line 12))\n",
      "  Obtaining dependency information for triton==3.1.0 from https://files.pythonhosted.org/packages/86/17/d9a5cf4fcf46291856d1e90762e36cbabd2a56c7265da0d1d9508c8e3943/triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting sympy==1.13.1 (from torch->-r requirements.txt (line 12))\n",
      "  Obtaining dependency information for sympy==1.13.1 from https://files.pythonhosted.org/packages/b2/fe/81695a1aa331a842b582453b605175f419fe8540355886031328089d840a/sympy-1.13.1-py3-none-any.whl.metadata\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch->-r requirements.txt (line 12))\n",
      "  Obtaining dependency information for mpmath<1.4,>=1.1.0 from https://files.pythonhosted.org/packages/43/e3/7d92a15f894aa0c9c4b49b8ee9ac9850d6e63b03c9c32c0367a13ae62209/mpmath-1.3.0-py3-none-any.whl.metadata\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/app-root/lib64/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.11->-r requirements.txt (line 3)) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/app-root/lib64/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.11->-r requirements.txt (line 3)) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/app-root/lib64/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.11->-r requirements.txt (line 3)) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/app-root/lib64/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.11->-r requirements.txt (line 3)) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/app-root/lib64/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.11->-r requirements.txt (line 3)) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /opt/app-root/lib64/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.11->-r requirements.txt (line 3)) (1.17.1)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/app-root/lib64/python3.11/site-packages (from anyio<5,>=3.5.0->openai==1.57.3->-r requirements.txt (line 8)) (3.10)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/app-root/lib64/python3.11/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->docling[tesserocr]~=2.8.3->-r requirements.txt (line 1)) (2.6)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.11->-r requirements.txt (line 4))\n",
      "  Obtaining dependency information for marshmallow<4.0.0,>=3.18.0 from https://files.pythonhosted.org/packages/ac/a7/a78ff54e67ef92a3d12126b98eb98ab8abab3de4a8c46d240c87e514d6bb/marshmallow-3.23.1-py3-none-any.whl.metadata\n",
      "  Downloading marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.11->-r requirements.txt (line 4))\n",
      "  Obtaining dependency information for typing-inspect<1,>=0.4.0 from https://files.pythonhosted.org/packages/65/f3/107a22063bf27bdccf2024833d3445f4eea42b2e598abfbd46f6a63b6cb0/typing_inspect-0.9.0-py3-none-any.whl.metadata\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting docutils!=0.21 (from deepsearch-glm<0.27.0,>=0.26.1->docling[tesserocr]~=2.8.3->-r requirements.txt (line 1))\n",
      "  Obtaining dependency information for docutils!=0.21 from https://files.pythonhosted.org/packages/8f/d7/9322c609343d929e75e7e5e6255e614fcc67572cfd083959cdef3b7aad79/docutils-0.21.2-py3-none-any.whl.metadata\n",
      "  Downloading docutils-0.21.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rich<14.0.0,>=13.7.0 (from deepsearch-glm<0.27.0,>=0.26.1->docling[tesserocr]~=2.8.3->-r requirements.txt (line 1))\n",
      "  Obtaining dependency information for rich<14.0.0,>=13.7.0 from https://files.pythonhosted.org/packages/19/71/39c7c0d87f8d4e6c020a393182060eaefeeae6c01dab6a84ec346f2567df/rich-13.9.4-py3-none-any.whl.metadata\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting tabulate>=0.8.9 (from deepsearch-glm<0.27.0,>=0.26.1->docling[tesserocr]~=2.8.3->-r requirements.txt (line 1))\n",
      "  Obtaining dependency information for tabulate>=0.8.9 from https://files.pythonhosted.org/packages/40/44/4a5f08c96eb108af5cb50b41f76142f0afa346dfa99d5296fe7202a11854/tabulate-0.9.0-py3-none-any.whl.metadata\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting jsonref<2.0.0,>=1.1.0 (from docling-core<3.0.0,>=2.6.1->docling[tesserocr]~=2.8.3->-r requirements.txt (line 1))\n",
      "  Obtaining dependency information for jsonref<2.0.0,>=1.1.0 from https://files.pythonhosted.org/packages/0c/ec/e1db9922bceb168197a558a2b8c03a7963f1afe93517ddd3cf99f202f996/jsonref-1.1.0-py3-none-any.whl.metadata\n",
      "  Downloading jsonref-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.16.0 in /opt/app-root/lib64/python3.11/site-packages (from docling-core<3.0.0,>=2.6.1->docling[tesserocr]~=2.8.3->-r requirements.txt (line 1)) (4.23.0)\n",
      "Collecting Pillow (from sentence-transformers==3.3.1->-r requirements.txt (line 11))\n",
      "  Obtaining dependency information for Pillow from https://files.pythonhosted.org/packages/ba/e5/8c68ff608a4203085158cff5cc2a3c534ec384536d9438c405ed6370d080/pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata\n",
      "  Downloading pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting jsonlines<4.0.0,>=3.1.0 (from docling-ibm-models<3.0.0,>=2.0.6->docling[tesserocr]~=2.8.3->-r requirements.txt (line 1))\n",
      "  Obtaining dependency information for jsonlines<4.0.0,>=3.1.0 from https://files.pythonhosted.org/packages/68/32/290ca20eb3a2b97ffa6ba1791fcafacb3cd2f41f539c96eb54cfc3cfcf47/jsonlines-3.1.0-py3-none-any.whl.metadata\n",
      "  Downloading jsonlines-3.1.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting opencv-python-headless<5.0.0.0,>=4.6.0.66 (from docling-ibm-models<3.0.0,>=2.0.6->docling[tesserocr]~=2.8.3->-r requirements.txt (line 1))\n",
      "  Obtaining dependency information for opencv-python-headless<5.0.0.0,>=4.6.0.66 from https://files.pythonhosted.org/packages/d1/09/248f86a404567303cdf120e4a301f389b68e3b18e5c0cc428de327da609c/opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting scikit-image (from easyocr<2.0,>=1.7->docling[tesserocr]~=2.8.3->-r requirements.txt (line 1))\n",
      "  Obtaining dependency information for scikit-image from https://files.pythonhosted.org/packages/ad/96/138484302b8ec9a69cdf65e8d4ab47a640a3b1a8ea3c437e1da3e1a5a6b8/scikit_image-0.24.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading scikit_image-0.24.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Collecting python-bidi (from easyocr<2.0,>=1.7->docling[tesserocr]~=2.8.3->-r requirements.txt (line 1))\n",
      "  Obtaining dependency information for python-bidi from https://files.pythonhosted.org/packages/59/61/c707bf04de816c3278943e3fb1378ca41a4381ea8fedf9ca2feba87748e6/python_bidi-0.6.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading python_bidi-0.6.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting Shapely (from easyocr<2.0,>=1.7->docling[tesserocr]~=2.8.3->-r requirements.txt (line 1))\n",
      "  Obtaining dependency information for Shapely from https://files.pythonhosted.org/packages/25/aa/53f145e5a610a49af9ac49f2f1be1ec8659ebd5c393d66ac94e57c83b00e/shapely-2.0.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading shapely-2.0.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting pyclipper (from easyocr<2.0,>=1.7->docling[tesserocr]~=2.8.3->-r requirements.txt (line 1))\n",
      "  Obtaining dependency information for pyclipper from https://files.pythonhosted.org/packages/c1/77/846a21957cd4ed266c36705ee340beaa923eb57d2bba013cfd7a5c417cfd/pyclipper-1.3.0.post6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading pyclipper-1.3.0.post6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
      "Collecting ninja (from easyocr<2.0,>=1.7->docling[tesserocr]~=2.8.3->-r requirements.txt (line 1))\n",
      "  Obtaining dependency information for ninja from https://files.pythonhosted.org/packages/62/54/787bb70e6af2f1b1853af9bab62a5e7cb35b957d72daf253b7f3c653c005/ninja-1.11.1.2-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata\n",
      "  Downloading ninja-1.11.1.2-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/app-root/lib64/python3.11/site-packages (from httpx<1,>=0.23.0->openai==1.57.3->-r requirements.txt (line 8)) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/app-root/lib64/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.57.3->-r requirements.txt (line 8)) (0.14.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/app-root/lib64/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers==3.3.1->-r requirements.txt (line 11)) (24.1)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.24->langchain==0.3.11->-r requirements.txt (line 3))\n",
      "  Obtaining dependency information for jsonpatch<2.0,>=1.33 from https://files.pythonhosted.org/packages/73/07/02e16ed01e04a374e644b575638ec7987ae846d25ad97bcc9945a3ee4b0e/jsonpatch-1.33-py2.py3-none-any.whl.metadata\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.3,>=0.1.17->langchain==0.3.11->-r requirements.txt (line 3))\n",
      "  Obtaining dependency information for orjson<4.0.0,>=3.9.14 from https://files.pythonhosted.org/packages/98/7e/8d5835449ddd873424ee7b1c4ba73a0369c1055750990d824081652874d6/orjson-3.10.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading orjson-3.10.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m224.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.3,>=0.1.17->langchain==0.3.11->-r requirements.txt (line 3))\n",
      "  Obtaining dependency information for requests-toolbelt<2.0.0,>=1.0.0 from https://files.pythonhosted.org/packages/3f/51/d4db610ef29373b879047326cbf6fa98b6c1969d6f6dc423279de2b1be2c/requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting et-xmlfile (from openpyxl<4.0.0,>=3.1.5->docling[tesserocr]~=2.8.3->-r requirements.txt (line 1))\n",
      "  Obtaining dependency information for et-xmlfile from https://files.pythonhosted.org/packages/c1/8b/5fe2cc11fee489817272089c4203e679c63b570a5aaeb18d852ae3cbba6a/et_xmlfile-2.0.0-py3-none-any.whl.metadata\n",
      "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/app-root/lib64/python3.11/site-packages (from pandas>=1.2.4->pymilvus==2.5.0->-r requirements.txt (line 9)) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas>=1.2.4->pymilvus==2.5.0->-r requirements.txt (line 9))\n",
      "  Obtaining dependency information for pytz>=2020.1 from https://files.pythonhosted.org/packages/11/c3/005fcca25ce078d2cc29fd559379817424e94885510568bc1bc53d7d5846/pytz-2024.2-py2.py3-none-any.whl.metadata\n",
      "  Downloading pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas>=1.2.4->pymilvus==2.5.0->-r requirements.txt (line 9))\n",
      "  Obtaining dependency information for tzdata>=2022.7 from https://files.pythonhosted.org/packages/a6/ab/7e5f53c3b9d14972843a647d8d7a853969a58aecc7559cb3267302c94774/tzdata-2024.2-py2.py3-none-any.whl.metadata\n",
      "  Downloading tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain==0.3.11->-r requirements.txt (line 3))\n",
      "  Obtaining dependency information for annotated-types>=0.6.0 from https://files.pythonhosted.org/packages/78/b6/6307fbef88d9b5ee7421e68d78a9f162e0da4900bc5f5793f6d3d0e34fb8/annotated_types-0.7.0-py3-none-any.whl.metadata\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.23.4 (from pydantic<3.0.0,>=2.7.4->langchain==0.3.11->-r requirements.txt (line 3))\n",
      "  Obtaining dependency information for pydantic-core==2.23.4 from https://files.pythonhosted.org/packages/44/31/a3899b5ce02c4316865e390107f145089876dff7e1dfc770a231d836aed8/pydantic_core-2.23.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading pydantic_core-2.23.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting XlsxWriter>=0.5.7 (from python-pptx<2.0.0,>=1.0.2->docling[tesserocr]~=2.8.3->-r requirements.txt (line 1))\n",
      "  Obtaining dependency information for XlsxWriter>=0.5.7 from https://files.pythonhosted.org/packages/a7/ea/53d1fe468e63e092cf16e2c18d16f50c29851242f9dd12d6a66e0d7f0d02/XlsxWriter-3.2.0-py3-none-any.whl.metadata\n",
      "  Downloading XlsxWriter-3.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/app-root/lib64/python3.11/site-packages (from requests<3,>=2->langchain==0.3.11->-r requirements.txt (line 3)) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/app-root/lib64/python3.11/site-packages (from requests<3,>=2->langchain==0.3.11->-r requirements.txt (line 3)) (2.2.3)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain==0.3.11->-r requirements.txt (line 3))\n",
      "  Obtaining dependency information for greenlet!=0.4.17 from https://files.pythonhosted.org/packages/f7/4b/1c9695aa24f808e156c8f4813f685d975ca73c000c2a5056c514c64980f6/greenlet-3.1.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata\n",
      "  Downloading greenlet-3.1.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1,>=0.7->langchain-openai==0.2.12->-r requirements.txt (line 5))\n",
      "  Obtaining dependency information for regex>=2022.1.18 from https://files.pythonhosted.org/packages/bf/ce/0d0e61429f603bac433910d99ef1a02ce45a8967ffbe3cbee48599e62d88/regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m197.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers<0.22,>=0.21 (from transformers<5.0.0,>=4.41.0->sentence-transformers==3.3.1->-r requirements.txt (line 11))\n",
      "  Obtaining dependency information for tokenizers<0.22,>=0.21 from https://files.pythonhosted.org/packages/22/06/69d7ce374747edaf1695a4f61b83570d91cc8bbfc51ccfecf76f56ab4aac/tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.41.0->sentence-transformers==3.3.1->-r requirements.txt (line 11))\n",
      "  Obtaining dependency information for safetensors>=0.4.1 from https://files.pythonhosted.org/packages/e6/ee/69e498a892f208bd1da4104d4b9be887f8611bf4942144718b6738482250/safetensors-0.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading safetensors-0.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting click>=8.0.0 (from typer<0.13.0,>=0.12.5->docling[tesserocr]~=2.8.3->-r requirements.txt (line 1))\n",
      "  Obtaining dependency information for click>=8.0.0 from https://files.pythonhosted.org/packages/00/2e/d53fa4befbf2cfa713304affc7ca780ce4fc1fd8710527771b58311a3229/click-8.1.7-py3-none-any.whl.metadata\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer<0.13.0,>=0.12.5->docling[tesserocr]~=2.8.3->-r requirements.txt (line 1))\n",
      "  Obtaining dependency information for shellingham>=1.3.0 from https://files.pythonhosted.org/packages/e0/f9/0595336914c5619e5f28a1fb793285925a8cd4b432c9da0a987836c7f822/shellingham-1.5.4-py2.py3-none-any.whl.metadata\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting pyarrow>=15.0.0 (from datasets->ragas==0.2.8->-r requirements.txt (line 14))\n",
      "  Obtaining dependency information for pyarrow>=15.0.0 from https://files.pythonhosted.org/packages/5e/b5/9e14e9f7590e0eaa435ecea84dabb137284a4dbba7b3c337b58b65b76d95/pyarrow-18.1.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata\n",
      "  Downloading pyarrow-18.1.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets->ragas==0.2.8->-r requirements.txt (line 14))\n",
      "  Obtaining dependency information for dill<0.3.9,>=0.3.0 from https://files.pythonhosted.org/packages/c9/7a/cef76fd8438a42f96db64ddaa85280485a9c395e7df3db8158cfec1eee34/dill-0.3.8-py3-none-any.whl.metadata\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting xxhash (from datasets->ragas==0.2.8->-r requirements.txt (line 14))\n",
      "  Obtaining dependency information for xxhash from https://files.pythonhosted.org/packages/d9/72/9256303f10e41ab004799a4aa74b80b3c5977d6383ae4550548b24bd1971/xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets->ragas==0.2.8->-r requirements.txt (line 14))\n",
      "  Obtaining dependency information for multiprocess<0.70.17 from https://files.pythonhosted.org/packages/50/15/b56e50e8debaf439f44befec5b2af11db85f6e0f344c3113ae0be0593a91/multiprocess-0.70.16-py311-none-any.whl.metadata\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec[http]<=2024.9.0,>=2023.1.0 (from datasets->ragas==0.2.8->-r requirements.txt (line 14))\n",
      "  Obtaining dependency information for fsspec[http]<=2024.9.0,>=2023.1.0 from https://files.pythonhosted.org/packages/1d/a0/6aaea0c2fbea2f89bfd5db25fb1e3481896a423002ebe4e55288907a97a3/fsspec-2024.9.0-py3-none-any.whl.metadata\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/app-root/lib64/python3.11/site-packages (from jinja2->torch->-r requirements.txt (line 12)) (3.0.2)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->sentence-transformers==3.3.1->-r requirements.txt (line 11))\n",
      "  Obtaining dependency information for joblib>=1.2.0 from https://files.pythonhosted.org/packages/91/29/df4b9b42f2be0b623cbd5e2140cafcaa2bef0759a00b7b70104dcfe2fb51/joblib-1.4.2-py3-none-any.whl.metadata\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers==3.3.1->-r requirements.txt (line 11))\n",
      "  Obtaining dependency information for threadpoolctl>=3.1.0 from https://files.pythonhosted.org/packages/4b/2c/ffbf7a134b9ab11a67b0cf0726453cedd9c5043a4fe7a35d1cefa9a1bcfb/threadpoolctl-3.5.0-py3-none-any.whl.metadata\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/app-root/lib64/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.24->langchain==0.3.11->-r requirements.txt (line 3)) (3.0.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/app-root/lib64/python3.11/site-packages (from jsonschema<5.0.0,>=4.16.0->docling-core<3.0.0,>=2.6.1->docling[tesserocr]~=2.8.3->-r requirements.txt (line 1)) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/app-root/lib64/python3.11/site-packages (from jsonschema<5.0.0,>=4.16.0->docling-core<3.0.0,>=2.6.1->docling[tesserocr]~=2.8.3->-r requirements.txt (line 1)) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/app-root/lib64/python3.11/site-packages (from jsonschema<5.0.0,>=4.16.0->docling-core<3.0.0,>=2.6.1->docling[tesserocr]~=2.8.3->-r requirements.txt (line 1)) (0.20.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/app-root/lib64/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=1.2.4->pymilvus==2.5.0->-r requirements.txt (line 9)) (1.16.0)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich<14.0.0,>=13.7.0->deepsearch-glm<0.27.0,>=0.26.1->docling[tesserocr]~=2.8.3->-r requirements.txt (line 1))\n",
      "  Obtaining dependency information for markdown-it-py>=2.2.0 from https://files.pythonhosted.org/packages/42/d7/1ec15b46af6af88f19b8e5ffea08fa375d433c998b8a7639e76935c14f1f/markdown_it_py-3.0.0-py3-none-any.whl.metadata\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/app-root/lib64/python3.11/site-packages (from rich<14.0.0,>=13.7.0->deepsearch-glm<0.27.0,>=0.26.1->docling[tesserocr]~=2.8.3->-r requirements.txt (line 1)) (2.18.0)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.11->-r requirements.txt (line 4))\n",
      "  Obtaining dependency information for mypy-extensions>=0.3.0 from https://files.pythonhosted.org/packages/2a/e2/5d3f6ada4297caebe1a2add3b126fe800c96f56dbe5d1988a2cbe0b267aa/mypy_extensions-1.0.0-py3-none-any.whl.metadata\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/app-root/lib64/python3.11/site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain==0.3.11->-r requirements.txt (line 3)) (0.2.0)\n",
      "Collecting imageio>=2.33 (from scikit-image->easyocr<2.0,>=1.7->docling[tesserocr]~=2.8.3->-r requirements.txt (line 1))\n",
      "  Obtaining dependency information for imageio>=2.33 from https://files.pythonhosted.org/packages/5c/f9/f78e7f5ac8077c481bf6b43b8bc736605363034b3d5eb3ce8eb79f53f5f1/imageio-2.36.1-py3-none-any.whl.metadata\n",
      "  Downloading imageio-2.36.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image->easyocr<2.0,>=1.7->docling[tesserocr]~=2.8.3->-r requirements.txt (line 1))\n",
      "  Obtaining dependency information for tifffile>=2022.8.12 from https://files.pythonhosted.org/packages/50/0a/435d5d7ec64d1c8b422ac9ebe42d2f3b2ac0b3f8a56f5c04dd0f3b7ba83c/tifffile-2024.9.20-py3-none-any.whl.metadata\n",
      "  Downloading tifffile-2024.9.20-py3-none-any.whl.metadata (32 kB)\n",
      "Collecting lazy-loader>=0.4 (from scikit-image->easyocr<2.0,>=1.7->docling[tesserocr]~=2.8.3->-r requirements.txt (line 1))\n",
      "  Obtaining dependency information for lazy-loader>=0.4 from https://files.pythonhosted.org/packages/83/60/d497a310bde3f01cb805196ac61b7ad6dc5dcf8dce66634dc34364b20b4f/lazy_loader-0.4-py3-none-any.whl.metadata\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.7.0->deepsearch-glm<0.27.0,>=0.26.1->docling[tesserocr]~=2.8.3->-r requirements.txt (line 1))\n",
      "  Obtaining dependency information for mdurl~=0.1 from https://files.pythonhosted.org/packages/b3/38/89ba8ad64ae25be8de66a6d463314cf1eb366222074cfda9ee839c56a4b4/mdurl-0.1.2-py3-none-any.whl.metadata\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m216.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain-0.3.11-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_community-0.3.11-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_openai-0.2.12-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m205.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_milvus-0.1.7-py3-none-any.whl (23 kB)\n",
      "Downloading langchain_text_splitters-0.3.2-py3-none-any.whl (25 kB)\n",
      "Downloading openai-1.57.3-py3-none-any.whl (390 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m390.2/390.2 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pymilvus-2.5.0-py3-none-any.whl (212 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.8/212.8 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading sentence_transformers-3.3.1-py3-none-any.whl (268 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ragas-0.2.8-py3-none-any.whl (173 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.9/173.9 kB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl (906.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.5/906.5 MB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m85.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m272.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m65.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.20.1-cp311-cp311-manylinux1_x86_64.whl (7.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m71.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading deepsearch_glm-0.26.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading docling_core-2.9.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.1/87.1 kB\u001b[0m \u001b[31m287.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading docling_ibm_models-2.0.8-py3-none-any.whl (65 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.9/65.9 kB\u001b[0m \u001b[31m200.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading docling_parse-2.1.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.4/22.4 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading easyocr-1.7.2-py3-none-any.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading grpcio-1.67.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading huggingface_hub-0.26.5-py3-none-any.whl (447 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.8/447.8 kB\u001b[0m \u001b[31m162.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jiter-0.8.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (345 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.6/345.6 kB\u001b[0m \u001b[31m166.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.3.24-py3-none-any.whl (410 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 kB\u001b[0m \u001b[31m181.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langsmith-0.2.3-py3-none-any.whl (320 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.7/320.7 kB\u001b[0m \u001b[31m201.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lxml-5.3.0-cp311-cp311-manylinux_2_28_x86_64.whl (5.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading marko-2.1.2-py3-none-any.whl (42 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 kB\u001b[0m \u001b[31m126.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading milvus_lite-2.4.10-py3-none-manylinux2014_x86_64.whl (49.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.9/250.9 kB\u001b[0m \u001b[31m231.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-5.29.1-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m198.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.9/434.9 kB\u001b[0m \u001b[31m146.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.23.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_settings-2.6.1-py3-none-any.whl (28 kB)\n",
      "Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m278.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m299.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_pptx-1.0.2-py3-none-any.whl (472 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m120.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Rtree-1.3.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (543 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m543.2/543.2 kB\u001b[0m \u001b[31m106.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 MB\u001b[0m \u001b[31m65.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading SQLAlchemy-2.0.36-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Downloading tesserocr-2.7.1-cp311-cp311-manylinux_2_28_x86_64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m295.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.47.0-py3-none-any.whl (10.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading typer-0.12.5-py3-none-any.whl (47 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m214.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ujson-5.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m265.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m122.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading docling-2.8.3-py3-none-any.whl (93 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.8/93.8 kB\u001b[0m \u001b[31m252.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m77.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m284.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m265.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading docutils-0.21.2-py3-none-any.whl (587 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.4/587.4 kB\u001b[0m \u001b[31m117.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m240.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading greenlet-3.1.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (602 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m602.4/602.4 kB\u001b[0m \u001b[31m122.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m195.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonlines-3.1.0-py3-none-any.whl (8.6 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading jsonref-1.1.0-py3-none-any.whl (9.4 kB)\n",
      "Downloading marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m252.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m141.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m272.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading orjson-3.10.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (131 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.3/131.3 kB\u001b[0m \u001b[31m308.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-18.1.0-cp311-cp311-manylinux_2_28_x86_64.whl (40.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 MB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m508.0/508.0 kB\u001b[0m \u001b[31m198.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (792 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m792.7/792.7 kB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m157.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.4/242.4 kB\u001b[0m \u001b[31m252.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m435.0/435.0 kB\u001b[0m \u001b[31m173.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.6/346.6 kB\u001b[0m \u001b[31m236.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading XlsxWriter-3.2.0-py3-none-any.whl (159 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.9/159.9 kB\u001b[0m \u001b[31m302.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Downloading ninja-1.11.1.2-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.9/422.9 kB\u001b[0m \u001b[31m209.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyclipper-1.3.0.post6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (969 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m969.6/969.6 kB\u001b[0m \u001b[31m92.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_bidi-0.6.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (286 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.6/286.6 kB\u001b[0m \u001b[31m270.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scikit_image-0.24.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.9/14.9 MB\u001b[0m \u001b[31m86.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading shapely-2.0.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m296.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading imageio-2.36.1-py3-none-any.whl (315 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.4/315.4 kB\u001b[0m \u001b[31m281.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m253.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Downloading tifffile-2024.9.20-py3-none-any.whl (228 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.2/228.2 kB\u001b[0m \u001b[31m306.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: tesserocr, pytz, python-bidi, pyclipper, mpmath, filetype, appdirs, xxhash, XlsxWriter, ujson, tzdata, tqdm, threadpoolctl, tenacity, tabulate, sympy, shellingham, safetensors, rtree, regex, python-dotenv, pysbd, pypdfium2, pydantic-core, pyarrow, protobuf, Pillow, orjson, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, ninja, networkx, mypy-extensions, mdurl, marshmallow, marko, lxml, lazy-loader, jsonref, jsonpatch, jsonlines, joblib, jiter, httpx-sse, grpcio, greenlet, fsspec, filelock, et-xmlfile, einops, docutils, distro, dill, click, annotated-types, typing-inspect, triton, tiktoken, tifffile, SQLAlchemy, Shapely, scipy, requests-toolbelt, python-pptx, python-docx, pydantic, pandas, openpyxl, opencv-python-headless, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, milvus-lite, markdown-it-py, imageio, huggingface-hub, docling-parse, tokenizers, scikit-learn, scikit-image, rich, pymilvus, pydantic-settings, openai, nvidia-cusolver-cu12, langsmith, dataclasses-json, typer, transformers, torch, langchain-core, docling-core, datasets, torchvision, sentence-transformers, langchain-text-splitters, langchain-openai, langchain-milvus, deepsearch-glm, langchain, easyocr, docling-ibm-models, langchain-community, docling, ragas\n",
      "Successfully installed Pillow-10.4.0 SQLAlchemy-2.0.36 Shapely-2.0.6 XlsxWriter-3.2.0 annotated-types-0.7.0 appdirs-1.4.4 click-8.1.7 dataclasses-json-0.6.7 datasets-3.2.0 deepsearch-glm-0.26.2 dill-0.3.8 distro-1.9.0 docling-2.8.3 docling-core-2.9.0 docling-ibm-models-2.0.8 docling-parse-2.1.2 docutils-0.21.2 easyocr-1.7.2 einops-0.8.0 et-xmlfile-2.0.0 filelock-3.16.1 filetype-1.2.0 fsspec-2024.9.0 greenlet-3.1.1 grpcio-1.67.1 httpx-sse-0.4.0 huggingface-hub-0.26.5 imageio-2.36.1 jiter-0.8.2 joblib-1.4.2 jsonlines-3.1.0 jsonpatch-1.33 jsonref-1.1.0 langchain-0.3.11 langchain-community-0.3.11 langchain-core-0.3.24 langchain-milvus-0.1.7 langchain-openai-0.2.12 langchain-text-splitters-0.3.2 langsmith-0.2.3 lazy-loader-0.4 lxml-5.3.0 markdown-it-py-3.0.0 marko-2.1.2 marshmallow-3.23.1 mdurl-0.1.2 milvus-lite-2.4.10 mpmath-1.3.0 multiprocess-0.70.16 mypy-extensions-1.0.0 networkx-3.4.2 ninja-1.11.1.2 numpy-1.26.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 openai-1.57.3 opencv-python-headless-4.10.0.84 openpyxl-3.1.5 orjson-3.10.12 pandas-2.2.3 protobuf-5.29.1 pyarrow-18.1.0 pyclipper-1.3.0.post6 pydantic-2.9.2 pydantic-core-2.23.4 pydantic-settings-2.6.1 pymilvus-2.5.0 pypdfium2-4.30.0 pysbd-0.3.4 python-bidi-0.6.3 python-docx-1.1.2 python-dotenv-1.0.1 python-pptx-1.0.2 pytz-2024.2 ragas-0.2.8 regex-2024.11.6 requests-toolbelt-1.0.0 rich-13.9.4 rtree-1.3.0 safetensors-0.4.5 scikit-image-0.24.0 scikit-learn-1.6.0 scipy-1.14.1 sentence-transformers-3.3.1 shellingham-1.5.4 sympy-1.13.1 tabulate-0.9.0 tenacity-9.0.0 tesserocr-2.7.1 threadpoolctl-3.5.0 tifffile-2024.9.20 tiktoken-0.8.0 tokenizers-0.21.0 torch-2.5.1 torchvision-0.20.1 tqdm-4.67.1 transformers-4.47.0 triton-3.1.0 typer-0.12.5 typing-inspect-0.9.0 tzdata-2024.2 ujson-5.10.0 xxhash-3.5.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98a3532-1ed4-4671-bea4-5e35f64da2bf",
   "metadata": {},
   "source": [
    "### Model inference parameters\n",
    "\n",
    "The parameters to the fine tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "304b4bcd-ed99-4d70-aa8a-b4586a9a4966",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T17:29:44.003314Z",
     "start_time": "2024-11-11T17:29:43.622611Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import yaml\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from typing import Iterator\n",
    "from pathlib import Path\n",
    "from openai import OpenAI\n",
    "\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.document_loaders import BaseLoader\n",
    "from langchain_core.documents import Document as LCDocument\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.llms import VLLMOpenAI\n",
    "from langchain_milvus import Milvus\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "from docling.document_converter import DocumentConverter\n",
    "\n",
    "def replace_special_char(original_str):\n",
    "    return re.sub(r\"[^\\w]\", \"_\", original_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "850fa004651738c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T16:06:05.072056Z",
     "start_time": "2024-11-11T16:06:05.068240Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "681ca2a6-523d-4a83-a102-270f5747bb00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T16:49:29.825470Z",
     "start_time": "2024-11-11T16:49:29.823451Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_TOKENS=2048\n",
    "TEMPERATURE=0.00"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a2c060-ea3e-4bbe-8f3a-3c2e5605c2e4",
   "metadata": {},
   "source": [
    "### Milvus connection info\n",
    "\n",
    "Defaults to local db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b655969f-53fb-4917-8a7e-1ee480402524",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T16:49:30.422387Z",
     "start_time": "2024-11-11T16:49:30.420015Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MILVUS_URI = os.getenv(\"MILVUS_URI\", \"./milvus_llm_judge_eval.db\")\n",
    "MILVUS_USERNAME = os.getenv(\"MILVUS_USERNAME\", \"\")\n",
    "MILVUS_PASSWORD = os.getenv(\"MILVUS_PASSWORD\", \"\")\n",
    "MILVUS_COLLECTION = os.getenv(\"MILVUS_COLLECTION\", \"my_org_documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3420575b-4d00-458b-aa0e-7030008ccd53",
   "metadata": {},
   "source": [
    "## Sanity check model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a20e7d20fe421c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T17:35:05.934496Z",
     "start_time": "2024-11-11T17:35:05.931578Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_llm(testing_config):\n",
    "    if testing_config.get(\"model_type\") == \"openai\":\n",
    "        print(\"Creating OpenAI model\")\n",
    "        return ChatOpenAI(\n",
    "            openai_api_key=re.sub(r\"\\s+\", \"\", testing_config[\"api_key\"]),\n",
    "            model=testing_config[\"model_name\"],\n",
    "            streaming=False\n",
    "        )\n",
    "    print(\"Creating VLLM model\")\n",
    "    return VLLMOpenAI(\n",
    "        openai_api_key=re.sub(r\"\\s+\", \"\", testing_config[\"api_key\"]),\n",
    "        openai_api_base=testing_config[\"endpoint_url\"], #https://model...com/v1\n",
    "        model_name=testing_config[\"model_name\"],\n",
    "        temperature=0.00,\n",
    "        max_tokens=2048,\n",
    "        streaming=False\n",
    "    )\n",
    "\n",
    "def qna_request(llm, template_str, question):\n",
    "    num_retries = 1\n",
    "    for attempt in range(num_retries):\n",
    "        try:\n",
    "            prompt = PromptTemplate.from_template(template_str)\n",
    "            chain = prompt | llm | StrOutputParser()\n",
    "            answer = chain.invoke({\"question\": question})        \n",
    "            print(answer)\n",
    "            return answer.strip()\n",
    "        except Exception as e:\n",
    "            print(f\"Request failed: {e}\")\n",
    "            if attempt + 1 < num_retries:\n",
    "                print(f\"Retrying in 5 seconds...\")\n",
    "                time.sleep(5)\n",
    "            else:\n",
    "                return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69188d06-d31e-4239-8be8-fdda029bfc0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T17:37:00.611124Z",
     "start_time": "2024-11-11T17:36:59.335850Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating VLLM model\n",
      "Artificial Intelligence (AI) is a multidisciplinary field of study within computer science that focuses on creating intelligent machines capable of performing tasks that would typically require human intelligence. These tasks include learning from experience, understanding natural language, recognizing patterns, solving problems, and making decisions. AI systems can be categorized into two main types: narrow or weak AI, designed to perform a specific task, and general or strong AI, which can perform any intellectual task that a human being can do.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Artificial Intelligence (AI) is a multidisciplinary field of study within computer science that focuses on creating intelligent machines capable of performing tasks that would typically require human intelligence. These tasks include learning from experience, understanding natural language, recognizing patterns, solving problems, and making decisions. AI systems can be categorized into two main types: narrow or weak AI, designed to perform a specific task, and general or strong AI, which can perform any intellectual task that a human being can do.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"llm_config.yaml\", \"r\") as f:\n",
    "    llm_config = yaml.safe_load(f)\n",
    "    \n",
    "llm = create_llm(llm_config[\"testing_config\"][0])\n",
    "template_str = llm_config[\"testing_config\"][0][\"qna_template\"]\n",
    "\n",
    "question = \"What is Artificial Intelligence?\"\n",
    "qna_request(llm, template_str, question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c961a7ae-d9d9-4cbc-9926-e1acaa6bc0f0",
   "metadata": {},
   "source": [
    "## Creating an Milvus DB with documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f598eb-8665-4240-91c0-3cc178aad88c",
   "metadata": {},
   "source": [
    "## Initial index creation and document ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cff5f7-c509-48db-90b5-e15815b8b530",
   "metadata": {},
   "source": [
    "#### Load pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54db9a89a16c5c07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T16:49:56.980781Z",
     "start_time": "2024-11-11T16:49:56.976636Z"
    }
   },
   "outputs": [],
   "source": [
    "class DoclingPDFLoader(BaseLoader):\n",
    "\n",
    "    def __init__(self, file_path: str | list[str]) -> None:\n",
    "        self._file_paths = file_path if isinstance(file_path, list) else [file_path]\n",
    "        self._converter = DocumentConverter()\n",
    "\n",
    "    def lazy_load(self) -> Iterator[LCDocument]:\n",
    "        for source in self._file_paths:\n",
    "            dl_doc = self._converter.convert(source).document\n",
    "            text = dl_doc.export_to_markdown()\n",
    "            yield LCDocument(page_content=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a968a5dd3653176",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T16:50:01.311171Z",
     "start_time": "2024-11-11T16:50:01.306759Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data_preparation/document_collection/ny_budget/fy25cp-en.pdf',\n",
       " '../data_preparation/document_collection/ny_policies/its-p19-005-open-source/its-p19-005-open-source.pdf',\n",
       " '../data_preparation/document_collection/ny_policies/nys-s16-001-new-york-state-universal-web-navigation/nys-s16-001-new-york-state-universal-web-navigation.pdf',\n",
       " '../data_preparation/document_collection/ny_policies/its-p10-003-its-telecommuting-policy/its-p10-003-its-telecommuting-policy.pdf',\n",
       " '../data_preparation/document_collection/ny_policies/nys-p08-003-domain-names-for-state-government/nys-p08-003-domain-names-for-state-government.pdf',\n",
       " '../data_preparation/document_collection/ny_policies/nys-s14-009_mobile_device_security/nys-s14-009_mobile_device_security.pdf',\n",
       " '../data_preparation/document_collection/ny_policies/its-p04-005-surplus-and-disposal-of-its-equipment-furniture-and-vehicles/its-p04-005-surplus-and-disposal-of-its-equipment-furniture-and-vehicles.pdf',\n",
       " '../data_preparation/document_collection/ny_policies/nys-p24-001-acceptable-use-of-artificial-intelligence-technologies-_1/nys-p24-001-acceptable-use-of-artificial-intelligence-technologies-_1.pdf']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_folder_path = \"../data_preparation/document_collection\"\n",
    "file_paths = [str(path) for path in Path(pdf_folder_path).rglob('*.pdf')]\n",
    "file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9a38809-2915-4376-a847-0cec2abbfd0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T16:50:06.934538Z",
     "start_time": "2024-11-11T16:50:06.871430Z"
    }
   },
   "outputs": [],
   "source": [
    "loader = DoclingPDFLoader(file_path=file_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4198fe0a-38bf-4cd4-af7d-35b41c645edd",
   "metadata": {},
   "source": [
    "#### Split documents into chunks with some overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6362934767fd34ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T16:50:42.830019Z",
     "start_time": "2024-11-11T16:50:08.192123Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Fetching 9 files: 100%|██████████| 9/9 [00:05<00:00,  1.55it/s]\n",
      "Downloading detection model, please wait. This may take several minutes depending upon your network connection.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |██████████████████████████████████████████████████| 100.0% Complete"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |██████████████████████████████████████████████████| 100.0% Complete"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: content stream objects stream 216 0 (content, offset 1800): parse error while reading object\n",
      "WARNING: content stream objects stream 217 0 (content, offset 291): treating unexpected array close token as null\n",
      "WARNING: content stream objects stream 217 0, content at offset 0: operation for array attempted on object of type string: treating as empty\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Document(metadata={}, page_content='<!-- image -->\\n\\n<!-- image -->')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1024,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "\n",
    "docs = loader.load()\n",
    "splits = text_splitter.split_documents(docs)\n",
    "splits[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae7eae2-c670-4eb5-803b-b4d591fa83db",
   "metadata": {},
   "source": [
    "#### Create the index and ingest the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53eb6d94-8615-4d55-b5b1-102f9ce56e6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T16:56:48.879756Z",
     "start_time": "2024-11-11T16:56:44.521087Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_381/3330881644.py:8: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n",
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
      "0it [00:00, ?it/s]\n",
      "A new version of the following files was downloaded from https://huggingface.co/nomic-ai/nomic-bert-2048:\n",
      "- configuration_hf_nomic_bert.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/nomic-ai/nomic-bert-2048:\n",
      "- modeling_hf_nomic_bert.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\" if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "model_kwargs = {\"trust_remote_code\": True, \"device\": device}\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"nomic-ai/nomic-embed-text-v1.5\",\n",
    "    model_kwargs=model_kwargs,\n",
    "    show_progress=True\n",
    ")\n",
    "\n",
    "db = Milvus(\n",
    "    embedding_function=embeddings,\n",
    "    connection_args={\n",
    "        \"uri\": MILVUS_URI,\n",
    "        \"user\": MILVUS_USERNAME, \n",
    "        \"password\": MILVUS_PASSWORD\n",
    "    },\n",
    "    collection_name=MILVUS_COLLECTION,\n",
    "    auto_id=True,\n",
    "    drop_old=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6bf425b-dffd-4f42-9537-49d41383182d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T16:56:54.933505Z",
     "start_time": "2024-11-11T16:56:52.374042Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 123/123 [00:55<00:00,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3909 documents loaded.\n"
     ]
    }
   ],
   "source": [
    "loaded = db.add_documents(splits)\n",
    "print(f\"{len(loaded)} documents loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae3b458-4979-46df-8493-7496764a2568",
   "metadata": {},
   "source": [
    "#### Test vector DB search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "489c6e6d-c42c-4de4-87cf-8edfd0e63da3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T16:57:07.580787Z",
     "start_time": "2024-11-11T16:57:07.452690Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 77.33it/s]\n"
     ]
    }
   ],
   "source": [
    "query = \"Who are the funding partners for the State's transformative infrastructure projects?\"\n",
    "docs_with_score = db.similarity_search_with_score(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90feeb37-7888-4c5f-a5cb-5f82637cec16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T16:57:08.188369Z",
     "start_time": "2024-11-11T16:57:08.185890Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Score:  146.87289428710938\n",
      "-  Invests in projects to improve the State's transit systems, modernize airports, and rebuild infrastructure to upgrade the State's transportation network. Several projects are expected to be financed from multiple funding sources and administered by public authorities (e.g., MTA, PANYNJ) outside of the State budget. Funding partners for these projects include the State, local governments, the Federal government, public authorities, and private entities. The FY 2025 Enacted Budget supports the State share of funding for these projects. Major infrastructure projects underway with funding partners are shown in the table below.\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Score:  208.61204528808594\n",
      "TRANSFORMATIVE INFRASTRUCTURE PROJECTS (billions of dollars)\n",
      "\n",
      "|                                |   Total Project  Costs |   State Share |   Other Funding  Partners Share  1 |\n",
      "|--------------------------------|------------------------|---------------|------------------------------------|\n",
      "| Transformative Projects Total  |                  109.6 |          11.7 |                               97.9 |\n",
      "| Gateway Tunnel Project  2      |                   16   |           1.3 |                               14.7 |\n",
      "| MTA Capital Plan 2020-2024  3  |                   52.1 |           3.1 |                               49   |\n",
      "| Commuter-First Penn Station  4 |                   22   |           7   |                               15   |\n",
      "| John F. Kennedy Airport        |                   19.5 |           0.3 |                               19.2 |\n",
      "\n",
      "- 4 State budget includes $1.3 billion appropriation to initiate the project. Funding shares still being determined.\n",
      "\n",
      "<!-- image -->\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Score:  248.90087890625\n",
      "-  Leverages ongoing Federal infrastructure funding. The Plan utilizes funding from the Federal infrastructure bills, IIJA and ARPA, to support new infrastructure investments, primarily for road and bridge projects, environmental programs, and broadband access.\n",
      "-  Maintains affordable debt levels while making significant capital investments. Specific actions taken by the State include:\n",
      "- o Sized capital investments to fit within the State's statutory debt limit over the 5-year period by prioritizing capital investments to maintain an affordable Capital Plan.\n",
      "- o Added $10 billion of cash resources, including an increase of $1 billion in the Enacted Budget, for PAYGO capital spending to improve debt affordability. This funding is being used to avoid the issuance of debt, by allowing the State to use cash to supplant borrowing for both higher-cost taxable debt and assets with short economic useful lives. The reduction in debt issuances provides both debt service savings and debt cap relief.\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Score:  258.8292236328125\n",
      "## State and Municipal Facilities\n",
      "\n",
      "The Capital Plan retains $1.9 billion in reappropriations for the State and Municipal Facilities Program. Entities eligible to receive grants under this program include: State agencies, local governments (e.g., counties, cities, towns, and villages), MTA, SUNY and CUNY senior and community colleges, private nonprofit colleges and universities, public school districts, public housing authorities, public libraries, fire districts, and other entities.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for doc, score in docs_with_score:\n",
    "    print(\"-\" * 80)\n",
    "    print(\"Score: \", score)\n",
    "    print(doc.page_content)\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d47df1-ec9b-4571-8864-0c2ff1051dbf",
   "metadata": {},
   "source": [
    "#### Test out RAG request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "289b702a5f57bd69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T17:42:28.713525Z",
     "start_time": "2024-11-11T17:42:28.707064Z"
    }
   },
   "outputs": [],
   "source": [
    "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 4})\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "def rag_request(llm, template_str, question):\n",
    "    num_retries = 1\n",
    "    for attempt in range(num_retries):\n",
    "        try:\n",
    "            prompt = PromptTemplate.from_template(template_str)\n",
    "            rag_chain = (\n",
    "                    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "                    | prompt\n",
    "                    | llm\n",
    "                    | StrOutputParser()\n",
    "            )\n",
    "            response = rag_chain.invoke(question)\n",
    "            return response.strip()\n",
    "        except Exception as e:\n",
    "            print(f\"Request failed: {e}\")\n",
    "            if attempt < num_retries:\n",
    "                print(f\"Retrying in 5 seconds...\")\n",
    "                time.sleep(5)\n",
    "            else:\n",
    "                return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f7855c9fe2ced63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T17:42:31.797639Z",
     "start_time": "2024-11-11T17:42:29.799731Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating VLLM model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 78.63it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The funding partners for the State's transformative infrastructure projects include the State, local governments, the Federal government, public authorities, and private entities. The table in the context provides a breakdown of the total project costs, the State's share, and the share of other funding partners. For example, the Gateway Tunnel Project has a total project cost of $16 billion, with the State's share being $1.3 billion and the share of other funding partners being $14.7 billion.\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = create_llm(llm_config[\"testing_config\"][0])\n",
    "template_str = llm_config[\"testing_config\"][0][\"rag_template\"]\n",
    "\n",
    "question = \"Who are the funding partners for the State's transformative infrastructure projects?\"\n",
    "result = rag_request(llm, template_str, question)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fe9c8d763f89d3",
   "metadata": {},
   "source": [
    "## Generate Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f44deb49353ef15",
   "metadata": {},
   "source": [
    "### Use qna.yaml, csv, jsonl to create some questions and ground truth answers\n",
    "\n",
    "We create a pandas dataframe with the columns `question` and `ground_truth`\n",
    "- create a csv file in the correct (default is \"ground_truth\") directory with the columns `question` and `ground_truth`\n",
    "\n",
    "- qna.yaml files can be taken as written from data_preparation and converted to the appropriate format.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "84d59e9b14117335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground_truth/qna.csv: 11 questions\n",
      "ground_truth/qna.jsonl: 13 questions\n",
      "ground_truth/qna.yaml: 15 questions\n",
      "39 total unique questions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What does an employee need to provide in an ap...</td>\n",
       "      <td>An employee needs to provide a request in writ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who is on the Telecommuting Appeal Board?</td>\n",
       "      <td>The telecommuting appeal board consists of a r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How long do employees have to wait until they ...</td>\n",
       "      <td>Employees who have been removed from the Telec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Should SE websites have sub-domain addresses?</td>\n",
       "      <td>SE websites should use short URLs over a separ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When should SE domain names use acronyms?</td>\n",
       "      <td>SE websites should avoid the use of acronyms u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What does an employee need to provide in an ap...   \n",
       "1          Who is on the Telecommuting Appeal Board?   \n",
       "2  How long do employees have to wait until they ...   \n",
       "3      Should SE websites have sub-domain addresses?   \n",
       "4          When should SE domain names use acronyms?   \n",
       "\n",
       "                                        ground_truth  \n",
       "0  An employee needs to provide a request in writ...  \n",
       "1  The telecommuting appeal board consists of a r...  \n",
       "2  Employees who have been removed from the Telec...  \n",
       "3  SE websites should use short URLs over a separ...  \n",
       "4  SE websites should avoid the use of acronyms u...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"llm_config.yaml\", \"r\") as f:\n",
    "    llm_config = yaml.safe_load(f)\n",
    "\n",
    "directory = \"ground_truth\"\n",
    "output_directory = llm_config.get(\"name\", \"output\")\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "qround_truth_df = pd.DataFrame(columns=[\"question\", \"ground_truth\"])\n",
    "\n",
    "for file_path in Path(directory).rglob('*.csv'):\n",
    "    # print(file_path)\n",
    "    csv_df = pd.read_csv(file_path)\n",
    "    print(f\"{file_path}: {csv_df.shape[0]} questions\")\n",
    "    qround_truth_df = pd.concat([qround_truth_df, csv_df], ignore_index=True)\n",
    "\n",
    "for file_path in Path(directory).rglob('*.jsonl'):\n",
    "    # print(file_path)\n",
    "    jsonl_df = pd.read_json(file_path, orient=\"records\", lines=True)\n",
    "    print(f\"{file_path}: {jsonl_df.shape[0]} questions\")\n",
    "    qround_truth_df = pd.concat([qround_truth_df, jsonl_df], ignore_index=True)\n",
    "\n",
    "qna_list = []\n",
    "\n",
    "for file_path in Path(directory).rglob('*.yaml'):\n",
    "    with open(file_path) as file:\n",
    "        qna = yaml.load(file, Loader=yaml.FullLoader)\n",
    "        for seed_example in qna[\"seed_examples\"]:\n",
    "            for questions_and_answers in seed_example[\"questions_and_answers\"]:\n",
    "                qna_list.append({\n",
    "                    \"question\": questions_and_answers[\"question\"].strip(),\n",
    "                    \"ground_truth\": questions_and_answers[\"answer\"].strip()\n",
    "                })\n",
    "        print(f\"{file_path}: {len(qna_list)} questions\")\n",
    "\n",
    "ground_truth_df = pd.concat([qround_truth_df, pd.DataFrame(qna_list)], ignore_index=True)\n",
    "ground_truth_df = ground_truth_df.drop_duplicates(subset=[\"question\"])\n",
    "print(f\"{ground_truth_df.shape[0]} total unique questions\")\n",
    "\n",
    "ground_truth_df.to_json(f\"{output_directory}/ground_truth.jsonl\", orient=\"records\", lines=True)\n",
    "ground_truth_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621433ec840ce28b",
   "metadata": {},
   "source": [
    "## Get responses from each of the available models with and without RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "45ba1106-731a-4477-877e-2c0769fb6e0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T17:44:24.813221Z",
     "start_time": "2024-11-11T17:42:59.236414Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating VLLM model\n",
      "0 What does an employee need to provide in\n",
      "In an appeal to the Telecommuting Appeal Board, an employee typically needs to provide a written request with reasons for disagreement with the determination made by the Telecommuting Program Coordinator. This request should include any new information or evidence that supports the employee's case. The employee may also have the opportunity to present their case in person during a hearing before the Appeal Board. It's important to note that the specific requirements for an appeal may vary depending on the organization, so it's always a good idea to check the relevant policies and guidelines for the most accurate information.\n",
      "QnA Answer: In an appeal to the Telecommuting Appeal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 79.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: In an appeal to the Telecommuting Appeal\n",
      "1 Who is on the Telecommuting Appeal Board\n",
      "The Telecommuting Appeal Board typically consists of three members. These members are selected from various departments within the organization to ensure a fair and unbiased review of telecommuting appeals. The specific departments and roles of the members can vary depending on the organization, but they are chosen to bring a diverse set of perspectives and expertise to the decision-making process.\n",
      "QnA Answer: The Telecommuting Appeal Board typically\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 79.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: The Telecommuting Appeal Board consists \n",
      "2 How long do employees have to wait until\n",
      "Employees must wait six months before submitting a new application for the telecommuting program. This waiting period allows them to demonstrate their commitment and performance in the current telecommuting arrangement before applying again.\n",
      "QnA Answer: Employees must wait six months before su\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 79.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: Employees who have had their application\n",
      "3 Should SE websites have sub-domain addre\n",
      "Yes, SE (State Entity) websites should have sub-domain addresses. Sub-domain addresses, such as \"agency\\_name\".ny.gov or \"program\\_name\".ny.gov, are highly recommended for SE websites. Using these addresses ensures that the public can easily recognize official state sites and helps maintain brand consistency. Additionally, sub-domain addresses are preferred over using only the ny.gov domain, as they provide more flexibility in managing and customizing the site's appearance and functionality.\n",
      "QnA Answer: Yes, SE (State Entity) websites should h\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 83.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: Yes, SE websites should use short URLs o\n",
      "4 When should SE domain names use acronyms\n",
      "SE (State Entity) domain names should use acronyms in specific cases to optimize user experience and branding. Acronyms can help users quickly recognize the organization's name and reduce cognitive load. However, they should be used judiciously to avoid confusion and ensure accessibility for all users, including those who may not be familiar with the acronym.\n",
      "\n",
      "Additionally, SEs should consider the following guidelines when using acronyms in domain names:\n",
      "\n",
      "1. **Consistency:** Use the acronym consistently across all platforms and communications.\n",
      "2. **Expansion:** Explain the acronym on first use or provide a link to a glossary for users who are unfamiliar with it.\n",
      "3. **Legibility:** Ensure that the acronym is easily readable and recognizable.\n",
      "4. **Accessibility:** Avoid using acronyms that may be confusing or difficult to pronounce for users with disabilities.\n",
      "5. **Branding:** Use acronyms to strengthen the brand and make it more memorable.\n",
      "\n",
      "By following these guidelines, SEs can effectively use acronyms in domain names to improve user experience and branding while ensuring accessibility and consistency.\n",
      "QnA Answer: SE (State Entity) domain names should us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 78.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: SE domain names should use acronyms only\n",
      "5 Can SE domain names contail special char\n",
      "Yes, SE (State Entity) domain names can contain special characters. However, it's important to note that the use of special characters in domain names can affect their functionality and usability. Therefore, it's recommended to consult with a domain name expert or your SE's IT department to ensure that the chosen domain name meets the necessary requirements and guidelines for your specific use case.\n",
      "QnA Answer: Yes, SE (State Entity) domain names can \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 81.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: No, SE domain names cannot contain speci\n",
      "6 Should OSS options be considered first f\n",
      "No, OSS (Open Source Software) options should not be considered first for all potential ITS software solutions. While OSS can be a valuable option for certain projects due to its cost-effectiveness, flexibility, and community support, it may not always be the best fit for all use cases. Factors such as the complexity of the project, the need for proprietary features, and the availability of skilled support should all be taken into account when evaluating software options.\n",
      "QnA Answer: No, OSS (Open Source Software) options s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 87.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: Yes, OSS options should be considered fi\n",
      "7 What conditions should OSS meet to be us\n",
      "Open Source Software (OSS) should meet the following conditions to be used as an ITS (Information Technology Services) software solution:\n",
      "\n",
      "1. **Quality and Maturity**: The OSS should have a proven track record, a stable codebase, and a well-established community that can provide support, maintenance, and updates.\n",
      "\n",
      "2. **Security**: ITS places a high priority on security. The OSS should have a solid security record, with no known vulnerabilities or security issues that could compromise the system or sensitive data.\n",
      "\n",
      "3. **Licensing**: The OSS should be licensed in a way that is consistent with ITS policies and allows for the use, modification, and distribution of the software as needed.\n",
      "\n",
      "4. **Support**: ITS should have access to adequate support and resources to ensure the successful implementation and maintenance of the OSS.\n",
      "\n",
      "5. **Compliance**: The OSS should comply with all relevant laws, regulations, and policies, including those related to data privacy, security, and intellectual property.\n",
      "\n",
      "6. **Integration**: The OSS should be able to integrate with existing ITS systems and infrastructure, and should not introduce significant compatibility issues or additional support requirements.\n",
      "\n",
      "7. **Scalability**: The OSS should be able to scale to meet the needs of the system and should not introduce performance issues or limitations.\n",
      "\n",
      "8. **Training**: ITS should have access to adequate training and resources to ensure that staff are able to effectively use and maintain the OSS.\n",
      "\n",
      "9. **Risk Management**: ITS should have a clear risk management strategy in place to address potential issues or concerns related to the use of OSS.\n",
      "\n",
      "10. **Vendor Management**: ITS should have a clear vendor management strategy in place to ensure that the OSS vendor is meeting all relevant requirements and expectations.\n",
      "\n",
      "By considering these factors, ITS can ensure that the OSS it chooses to use is of high quality, secure, and well-supported, and that it meets the needs of the system and its users.\n",
      "QnA Answer: Open Source Software (OSS) should meet t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 82.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: OSS should meet the following four condi\n",
      "8 Who approves software licenses for ITS?\n",
      "The ITS Division of Legal Affairs (DLA) is responsible for approving software licenses for ITS. This ensures that the licenses used by ITS comply with all relevant laws and regulations, and that the terms of the license are fair and reasonable for the agency.\n",
      "QnA Answer: The ITS Division of Legal Affairs (DLA) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 82.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: The ITS Division of Legal Affairs (DLA) \n",
      "9 What are examples of ITS E-equipment?\n",
      "Examples of ITS E-equipment include, but are not limited to, desktops, laptops, mobile devices, servers, mobile devices, video conferencing equipment, copiers, printers, and data center equipment. This equipment is owned, leased, or maintained by the State and is used to support ongoing business functions.\n",
      "QnA Answer: Examples of ITS E-equipment include, but\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 83.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: ITS E-equipment refers to hardware used \n",
      "10 What ITS guidelines must be followed whe\n",
      "The ITS (Information Technology Standards) guidelines that must be followed when disposing of end-of-life E-equipment include the 46 CFR Part 168 and 169. These regulations are established by the United States Coast Guard and apply to the disposal of E-equipment. It is essential to adhere to these guidelines to ensure proper handling and disposal of electronic waste, protecting both the environment and personal data.\n",
      "QnA Answer: The ITS (Information Technology Standard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 84.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: The ITS guidelines that must be followed\n",
      "11 What must be submitted once ITS E-equipm\n",
      "An ITSM ServiceNow Surplus/LDA Service Request must be submitted once ITS E-equipment is prepared for surplus or disposal.\n",
      "QnA Answer: An ITSM ServiceNow Surplus/LDA Service R\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 83.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: An ITSM ServiceNow Surplus/LDA Service R\n",
      "12 What is the purpose of the Use of Artifi\n",
      "The Use of Artificial Intelligence policy is designed to govern the use of AI systems within the State Engineering (SE) division. The policy aims to ensure that SE leadership approves all AI systems, establishes guidelines for acceptable use, and identifies appropriate oversight. It also emphasizes the importance of transparency, fairness, and accountability in AI system development and deployment. Additionally, the policy highlights the need to address potential biases and discrimination, and to comply with relevant laws, regulations, and policies. Furthermore, it underscores the importance of data management, security, and privacy in AI system use. Overall, the Use of Artificial Intelligence policy seeks to promote responsible and ethical AI use within the SE division.\n",
      "QnA Answer: The Use of Artificial Intelligence polic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 81.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: The purpose of the Use of Artificial Int\n",
      "13 What is the benefit of the Use of Artifi\n",
      "The benefit of the Use of Artificial Intelligence policy is that it encourages the responsible use of AI technologies, ensuring that they are used ethically and effectively to drive innovation, increase operational efficiencies, and better serve New Yorkers while protecting privacy, managing risk, promoting accountability, safety, and equity, and complying with all applicable laws, regulations, and policies.\n",
      "QnA Answer: The benefit of the Use of Artificial Int\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 81.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: The benefit of the Use of Artificial Int\n",
      "14 Are the guidelines on the use of Artific\n",
      "The guidelines on the use of Artificial Intelligence are not a policy or a standard. They are more accurately described as a set of principles or guiding values. These principles provide a framework for responsible AI use, but they do not have the same legal standing as a policy or standard. A policy typically outlines specific rules and regulations, while a standard refers to a widely accepted set of practices or technical specifications. The guidelines on AI use, however, are more flexible and open-ended, allowing for interpretation and adaptation to various contexts.\n",
      "QnA Answer: The guidelines on the use of Artificial \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 84.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: The guidelines on the use of Artificial \n",
      "15 Who can I email if I have a question abo\n",
      "You can email its.sm.dla@its.ny.gov for any questions about ITS policies and standards for technology use. This email address is specifically designated for inquiries related to ITS policies and standards, and it is likely to be staffed by knowledgeable individuals who can provide accurate and helpful information.\n",
      "QnA Answer: You can email its.sm.dla@its.ny.gov for \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 84.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: You can email the Chief Data Office at c\n",
      "16 Where can I find policies, standards, an\n",
      "The policies, standards, and guidelines for New York State technology policies can be found on the official New York State Office of Information Technology Services (ITS) website. This centralized resource provides access to a wide range of technology policies, ensuring that all stakeholders have access to the most up-to-date and accurate information.\n",
      "QnA Answer: The policies, standards, and guidelines \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 79.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: The policies, standards, and guidelines \n",
      "17 What is the telephone number to submit i\n",
      "The telephone number to submit inquiries and requests about ITS policies and standards is 518-473-5115. This number is specifically dedicated to handling questions and requests related to ITS policies and standards, providing a direct line of communication for clarification and assistance.\n",
      "QnA Answer: The telephone number to submit inquiries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 84.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: The telephone number to submit inquiries\n",
      "18 What was the change made to the ITS poli\n",
      "The change made to the ITS policy on the surplus and disposal of equipment in January 2011 was the addition of a section for the surplus and disposal of E-equipment. This update was made to ensure that the policy covered all types of equipment being surplus or disposed of by ITS.\n",
      "QnA Answer: The change made to the ITS policy on the\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 84.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: The change made to the ITS policy on the\n",
      "19 Who have been the reviewers on changes t\n",
      "The reviewers on changes to the ITS policy for the disposal of equipment are John Doe and Jane Doe.\n",
      "QnA Answer: The reviewers on changes to the ITS poli\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 80.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: The ITS policy for the disposal of equip\n",
      "20 When was the policy on the surplus and d\n",
      "The policy on the surplus and disposal of ITS (New York State Office of Information Technology Services) equipment was first created in 2004. This policy outlines the process for handling ITS equipment that is no longer needed or used, and it is established to ensure that such equipment is disposed of in a secure, environmentally responsible, and cost-effective manner.\n",
      "QnA Answer: The policy on the surplus and disposal o\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 82.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: The policy on the surplus and disposal o\n",
      "21 What are documents related to the ITS po\n",
      "The documents related to the ITS policy on surplus and disposal of equipment are the \"Surplus and Disposal of ITS Equipment, Furniture and Vehicles\" policy, the \"NYS-S13-003 Sanitization/Secure Disposal\" standard, the \"NYS-P03-002 Information Security Policy,\" and the \"NYS-P14-001 Acceptable Use of Information Technology Resources\" policy. These documents provide guidelines and procedures for the surplus and disposal of ITS equipment, furniture, and vehicles, as well as ensure that proper security measures are taken when disposing of sensitive information.\n",
      "QnA Answer: The documents related to the ITS policy \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 83.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: The documents related to the ITS policy \n",
      "22 Which forms are related to the ITS polic\n",
      "The forms related to the ITS policy on surplus and disposal of equipment are the CS-201 Form, CS-201.1 Form, CS-201.2 Form, CS-201.3 Form, CS-202 Form, CS-202.1 Form, CS-202.2 Form, CS-202.3 Form, NYS-S13-003 Sanitization/Secure Disposal, ITS-201 Form, ITS-201.1 Form, ITS-201.2 Form, ITS-201.3 Form, ITS-202 Form, ITS-202.1 Form, ITS-202.2 Form, ITS-202.3 Form. These forms are used to facilitate the surplus and disposal process for ITS equipment in accordance with the established policy.\n",
      "QnA Answer: The forms related to the ITS policy on s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 81.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: The forms related to the ITS policy on s\n",
      "23 Are there documents related to the ITS p\n",
      "Yes, there are documents related to the ITS policy on surplus and disposal of equipment. These documents include the ITSM ServiceNow Surplus/LDA Service Request, the Report of Surplus Personal Property (CS-201) Form, the Report of Surplus Motor Vehicles and Motorized Equipment (CS-201.1) Form, NYS-S13-003 Sanitization/Secure Disposal, and ITS-S18-001 Fleet Management Usage. These forms and guidelines are used to properly surplus and dispose of ITS-owned or managed electronic equipment, furniture, miscellaneous equipment, and vehicles when they are no longer needed.\n",
      "QnA Answer: Yes, there are documents related to the \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 75.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: Yes, there are several related documents\n",
      "24 Are some of the State's transformative i\n",
      "Yes, some of the State's transformative infrastructure projects are financed outside of the State budget. This means that funds for these projects come from sources other than the State's regular financial resources. These external funding sources can include federal grants, public-private partnerships, and private investments. By leveraging external funding, the State can potentially accelerate project delivery, reduce debt issuances, and achieve other financial benefits. However, it's important to note that the allocation and management of external funding for infrastructure projects can be complex and require careful coordination between various stakeholders.\n",
      "QnA Answer: Yes, some of the State's transformative \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 85.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: Yes, some of the State's transformative \n",
      "25 What is the State Share for the Gateway \n",
      "The State Share for the Gateway Tunnel Project is 1.3 billion dollars. This information is based on internal knowledge, as it represents the financial commitment made by the State of New Jersey towards the project.\n",
      "QnA Answer: The State Share for the Gateway Tunnel P\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 80.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: The State Share for the Gateway Tunnel P\n",
      "26 Who are the funding partners for the Sta\n",
      "The funding partners for the State's transformative infrastructure projects typically include the State itself, along with various funding partners such as local governments, the Federal government, public authorities, and private entities. This collaborative approach allows for the pooling of resources and expertise to finance and deliver large-scale, complex projects that benefit the entire state.\n",
      "QnA Answer: The funding partners for the State's tra\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 84.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: The funding partners for the State's tra\n",
      "27 What percent of State capital spending i\n",
      "The answer is 20 percent. This means that 20 percent of the State's capital spending in FY 2025 is expected to be funded by Federal aid. This information is based on the State's internal knowledge and is likely derived from their budgeting and financial planning processes.\n",
      "QnA Answer: The answer is 20 percent. This means tha\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 86.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: 19 percent of State capital spending in \n",
      "28 Is capital spending expected to increase\n",
      "Yes, capital spending is indeed expected to rise in FY 2025. This projection is based on the organization's financial outlook and strategic planning for the upcoming fiscal year. The increase in capital spending is likely to be driven by various factors, such as investments in infrastructure, research and development, and digital transformation initiatives. However, it is essential to monitor the actual spending figures and any potential adjustments that may be made during the fiscal year.\n",
      "QnA Answer: Yes, capital spending is indeed expected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 80.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: Yes, capital spending is expected to inc\n",
      "29 Why is State capital spending projected \n",
      "State capital spending is projected to rise in FY 2025 due to increased investments in economic development. This focus on economic development aims to create jobs, strengthen the economy, and promote growth. By allocating more resources towards capital spending, the state can directly contribute to these objectives and foster a more prosperous environment.\n",
      "QnA Answer: State capital spending is projected to r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 82.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: State capital spending is projected to i\n",
      "30 What is capital spending for the State p\n",
      "The State's capital spending is projected to be $17.7 billion in FY 2025. This figure represents the amount the State plans to invest in its infrastructure, including transportation, education, and environmental projects, among others. It's important to note that capital spending is a significant component of a country's economic growth, as it contributes to the development of physical infrastructure and the overall quality of life. In the case of the State of New York, a higher capital spending projection may indicate a stronger commitment to economic development and infrastructure improvements, which could have positive implications for the state's economy and residents.\n",
      "QnA Answer: The State's capital spending is projecte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: Capital spending for the State is projec\n",
      "31 What are new large scale projects in the\n",
      "The Five-Year DOT Capital Plan includes several new large-scale projects. One of them is the Interborough Express, which is a proposed 10-mile light rail system connecting Brooklyn, Queens, and the Bronx. This project aims to provide a more efficient and eco-friendly transportation option for the residents and businesses in these boroughs.\n",
      "\n",
      "Another significant project is the expansion of the Second Avenue Subway, which will increase capacity and improve accessibility in Manhattan. The project includes the construction of a new fully ADA compliant station at the West End Concourse and the expansion of the existing subway to the west.\n",
      "\n",
      "Additionally, the plan includes the modernization of the John F. Kennedy Airport, which will involve the transformation of the airport's eight disparate terminal sites into a unified JFK Airport. The project includes demolishing old terminals, utilizing vacant space, and utilizing new technologies to improve the airport's efficiency and passenger experience.\n",
      "\n",
      "Lastly, the plan includes the widening of the I-81 in Syracuse, which will convert the current Interstate into a boulevard and remove the elevated portion of the highway. This project aims to improve safety, traffic flow, and provide better access to neighborhoods surrounding the highway.\n",
      "\n",
      "These are just a few examples of the new large-scale projects in the Five-Year DOT Capital Plan. The plan also includes other projects such as the improvement of roads, bridges, and tunnels, as well as the expansion of public transportation systems across the state.\n",
      "QnA Answer: The Five-Year DOT Capital Plan includes \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 80.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: The new large scale projects in the Five\n",
      "32 How much does the DOT Capital plan inclu\n",
      "The DOT Capital Plan includes $1 billion for the \"Bridge NY\" program. This program focuses on the reconstruction, replacement, or repair of bridges across the State of New York, aiming to improve the overall condition and safety of the state's bridge infrastructure.\n",
      "QnA Answer: The DOT Capital Plan includes $1 billion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 81.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: The DOT Capital Plan includes $1 billion\n",
      "33 What percentage of existing State-releat\n",
      "The answer is 15%. This means that, based on current projections, one-fourth of the existing State-related debt is expected to be retired within 15 years. This information highlights the State's debt management and repayment strategy, which is an essential aspect of fiscal responsibility and financial planning.\n",
      "QnA Answer: The answer is 15%. This means that, base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 83.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: The percentage of existing State-related\n",
      "34 What does 100% State-releated debt retir\n",
      "100% State-related debt retirement refers to the complete repayment of all debt obligations that are directly linked to the State. This includes both principal and interest payments, and it signifies that the State has fulfilled its financial commitment to the debt. It is important to note that this does not include debt retirements funded by local governments or other entities, only debt issued by the State itself.\n",
      "QnA Answer: 100% State-related debt retirement refer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 81.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: 100% State-related debt retirement repre\n",
      "35 What impact does the rate of debt retire\n",
      "The rate of debt retirement has a significant impact on the State's financial health and flexibility. When debt is retired more quickly, the State saves money on interest payments over the life of the debt. This frees up resources that can be used for other priorities, such as education, infrastructure, or social services. Additionally, retiring debt more quickly can improve the State's credit rating, making it easier and cheaper to borrow money in the future. However, retiring debt more quickly may also limit the State's ability to use its debt as a financial tool to manage cash flow or invest in long-term projects. Therefore, the rate of debt retirement is an important consideration for the State's financial management.\n",
      "QnA Answer: The rate of debt retirement has a signif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 84.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: The rate at which State-related debt is \n",
      "36 How much will be appropriated on Communi\n",
      "The amount appropriated for Community Services Programs for people with development disabilities in FY 2026 is 132,113 thousand dollars.\n",
      "QnA Answer: The amount appropriated for Community Se\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 85.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: The answer cannot be determined from the\n",
      "37 What are the projected appropriations fr\n",
      "The projected appropriations for Non-Bondable Projects for people with developmental disabilities from FY 2025 to FY 2027 are as follows:\n",
      "\n",
      "* FY 2025: 1,000 thousand dollars\n",
      "* FY 2026: 1,000 thousand dollars\n",
      "* FY 2027: 1,000 thousand dollars\n",
      "\n",
      "These amounts remain constant for each fiscal year, totaling 3,000 thousand dollars over the three-year period.\n",
      "QnA Answer: The projected appropriations for Non-Bon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 82.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: The projected appropriations for Non-Bon\n",
      "38 What is the total projected appropriatio\n",
      "The total projected appropriation on programs for people with development disabilities in FY 2026 is 564,692 thousand dollars. This information is based on the internal knowledge and resources available to answer the question.\n",
      "QnA Answer: The total projected appropriation on pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 86.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: The total projected appropriation on pro\n",
      "Creating VLLM model\n",
      "0 What does an employee need to provide in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 83.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: An employee needs to provide a written r\n",
      "1 Who is on the Telecommuting Appeal Board\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 84.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: The Telecommuting Appeal Board consists \n",
      "2 How long do employees have to wait until\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 85.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: Employees who have been removed from the\n",
      "3 Should SE websites have sub-domain addre\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 84.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: Based on the provided context, SE websit\n",
      "4 When should SE domain names use acronyms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 83.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: SE domain names should use acronyms when\n",
      "5 Can SE domain names contail special char\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 75.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: No, SE domain names cannot contain speci\n",
      "6 Should OSS options be considered first f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 79.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: Yes, OSS options should be considered fi\n",
      "7 What conditions should OSS meet to be us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 68.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: To be used as an ITS software solution, \n",
      "8 Who approves software licenses for ITS?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 69.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: The ITS Division of Legal Affairs (DLA) \n",
      "9 What are examples of ITS E-equipment?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 75.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: Based on the provided context, examples \n",
      "10 What ITS guidelines must be followed whe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 74.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: The ITS guidelines that must be followed\n",
      "11 What must be submitted once ITS E-equipm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 73.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: Once ITS E-equipment is prepared for sur\n",
      "12 What is the purpose of the Use of Artifi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 71.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: The purpose of the Use of Artificial Int\n",
      "13 What is the benefit of the Use of Artifi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 81.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: The benefit of the Use of Artificial Int\n",
      "14 Are the guidelines on the use of Artific\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 79.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: The guidelines on the use of Artificial \n",
      "15 Who can I email if I have a question abo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 81.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: You can email the Chief Data Office at c\n",
      "16 Where can I find policies, standards, an\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 83.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: You can find policies, standards, and gu\n",
      "17 What is the telephone number to submit i\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 75.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: The telephone number to submit inquiries\n",
      "18 What was the change made to the ITS poli\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 81.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: The context does not provide information\n",
      "19 Who have been the reviewers on changes t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 84.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: The reviewers for changes to the ITS pol\n",
      "20 When was the policy on the surplus and d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 83.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: The policy on the surplus and disposal o\n",
      "21 What are documents related to the ITS po\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 83.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: The related documents to the ITS policy \n",
      "22 Which forms are related to the ITS polic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 84.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: The forms related to the ITS policy on s\n",
      "23 Are there documents related to the ITS p\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 83.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: Yes, there are related documents to the \n",
      "24 Are some of the State's transformative i\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 80.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: Yes, some of the State's transformative \n",
      "25 What is the State Share for the Gateway \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 84.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: The State Share for the Gateway Tunnel P\n",
      "26 Who are the funding partners for the Sta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 81.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: The funding partners for the State's tra\n",
      "27 What percent of State capital spending i\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 83.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: 19 percent of State capital spending in \n",
      "28 Is capital spending expected to increase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 84.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: Yes, capital spending is expected to inc\n",
      "29 Why is State capital spending projected \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 82.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: State capital spending is projected to i\n",
      "30 What is capital spending for the State p\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 84.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: Capital spending for the State is projec\n",
      "31 What are new large scale projects in the\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 84.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: The new large-scale projects in the Five\n",
      "32 How much does the DOT Capital plan inclu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 84.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: The DOT Capital Plan includes $1 billion\n",
      "33 What percentage of existing State-releat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 82.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: The percentage of existing State-related\n",
      "34 What does 100% State-releated debt retir\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 83.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: 100% State-related debt retirement would\n",
      "35 What impact does the rate of debt retire\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 84.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: The rate of debt retirement has a signif\n",
      "36 How much will be appropriated on Communi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 81.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: The context provided does not include sp\n",
      "37 What are the projected appropriations fr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 85.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: The context provided does not include sp\n",
      "38 What is the total projected appropriatio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 72.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: The total projected appropriation on pro\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "\n",
    "with open(\"llm_config.yaml\", \"r\") as f:\n",
    "    llm_config = yaml.safe_load(f)\n",
    "\n",
    "output_directory = llm_config.get(\"name\", \"output\")\n",
    "os.makedirs(output_directory, exist_ok=True)   \n",
    "    \n",
    "qna_df = pd.read_json(f\"{output_directory}/ground_truth.jsonl\", orient=\"records\", lines=True)\n",
    "\n",
    "for testing_config in llm_config[\"testing_config\"]:\n",
    "    answers = qna_df.copy()\n",
    "    answers[\"answer\"] = \"\"\n",
    "    answers[\"rag_answer\"] = \"\"\n",
    "    llm = create_llm(testing_config)\n",
    "    for index, row in answers.iterrows():\n",
    "        question = row[\"question\"]\n",
    "        print(index, question[:40])\n",
    "        if testing_config.get(\"qna_template\"):\n",
    "            answer = qna_request(llm, testing_config.get(\"qna_template\"), question)\n",
    "            if answer:\n",
    "                print(\"QnA Answer: \" + answer[:40])\n",
    "            answers.at[index, \"answer\"] = answer\n",
    "        if testing_config.get(\"rag_template\"):\n",
    "            answer = rag_request(llm, testing_config.get(\"rag_template\"), question)\n",
    "            if answer:\n",
    "                print(\"RAG Answer: \" + answer[:40])\n",
    "            answers.at[index, \"rag_answer\"] = answer\n",
    "    testing_config_name = replace_special_char(testing_config[\"name\" or \"model_name\"])\n",
    "    answers.to_json(f\"{output_directory}/{testing_config_name}_answers.jsonl\", orient=\"records\", lines=True)\n",
    "    # answers.to_csv(f\"{output_directory}/{base_filename}_answers.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bf0670-0bea-4807-b760-bf442824a17a",
   "metadata": {},
   "source": [
    "## Grade responses using Judge Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "13fa5c97-b204-474d-a395-f3acbfb50483",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T17:55:00.708041Z",
     "start_time": "2024-11-11T17:55:00.700102Z"
    }
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open(\"llm_config.yaml\", \"r\") as f:\n",
    "    llm_config = yaml.safe_load(f)\n",
    "\n",
    "output_directory = llm_config.get(\"name\", \"output\")\n",
    "os.makedirs(output_directory, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b3fde059-0fb1-4075-8e23-8609a33cad9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T18:11:45.782848Z",
     "start_time": "2024-11-11T18:11:45.779906Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "scoring_template_str = llm_config[\"judge\"].get(\"template\")\n",
    "assert scoring_template_str\n",
    "SCORING_PROMPT = PromptTemplate.from_template(scoring_template_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f877508f-fa77-4d53-8de3-d0ba4f837281",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T18:11:54.855577Z",
     "start_time": "2024-11-11T18:11:54.846308Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "judge_client = OpenAI(api_key=llm_config[\"judge\"][\"api_key\"])\n",
    "judge_model_name = llm_config[\"judge\"][\"model_name\"]\n",
    "\n",
    "\n",
    "def score_request(question, answer, reference_answer):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": SCORING_PROMPT.format(\n",
    "                question=question,\n",
    "                answer=answer,\n",
    "                reference_answer=reference_answer\n",
    "            )\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    completion = judge_client.chat.completions.create(\n",
    "        model=judge_model_name,\n",
    "        messages=messages,\n",
    "        n=1,\n",
    "        temperature=0.0,\n",
    "        max_tokens=1024,\n",
    "    )\n",
    "    response_content = completion.choices[0].message.content\n",
    "    # print(response_content)\n",
    "    response_content = re.sub(r'^```json', '', response_content)\n",
    "    response_content = re.sub(r'```$', '', response_content)\n",
    "    # print(response_content)\n",
    "    try:\n",
    "        result = json.loads(response_content)\n",
    "    except Exception as e:\n",
    "        result = {\"answer_quality\": 0, \"reasoning\": \"Error\"}\n",
    "        print(\"response_content:\", response_content)\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "    score = result[\"answer_quality\"]\n",
    "    reasoning = result[\"reasoning\"]\n",
    "    return score, reasoning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c8dcdb86-5272-45d6-92f4-71ea7e412599",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T18:24:21.624706Z",
     "start_time": "2024-11-11T18:12:10.647497Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "finetuned\n",
      "0 What does an employee need to provide in an appeal to the Telecommuting Appeal board?\n",
      "In an appeal to the Telecommuting Appeal 4 The reference answer specifies that an e\n",
      "In an appeal to the Telecommuting Appeal 4 The reference answer specifies that an e\n",
      "1 Who is on the Telecommuting Appeal Board?\n",
      "The Telecommuting Appeal Board typically 3 The reference answer specifies that the \n",
      "The Telecommuting Appeal Board consists  5 The reference answer states that the Tel\n",
      "2 How long do employees have to wait until they may submit a new application for the telecommuting program?\n",
      "Employees must wait six months before su 4 The reference answer states that employe\n",
      "Employees who have had their application 3 The reference answer states that employe\n",
      "3 Should SE websites have sub-domain addresses?\n",
      "Yes, SE (State Entity) websites should h 2 The reference answer suggests that SE we\n",
      "Yes, SE websites should use short URLs o 5 The reference answer states that SE webs\n",
      "4 When should SE domain names use acronyms?\n",
      "SE (State Entity) domain names should us 3 The reference answer provides a specific\n",
      "SE domain names should use acronyms only 4 The reference answer provides two condit\n",
      "5 Can SE domain names contail special characters?\n",
      "Yes, SE (State Entity) domain names can  2 The reference answer clearly states that\n",
      "No, SE domain names cannot contain speci 5 The reference answer states that SE doma\n",
      "6 Should OSS options be considered first for all potential ITS software solutions?\n",
      "No, OSS (Open Source Software) options s 1 The reference answer states that OSS opt\n",
      "Yes, OSS options should be considered fi 4 The reference answer provides two key fa\n",
      "7 What conditions should OSS meet to be used as an ITS software solution?\n",
      "Open Source Software (OSS) should meet t 3 The reference answer highlights three ke\n",
      "OSS should meet the following four condi 5 The reference answer lists four conditio\n",
      "8 Who approves software licenses for ITS?\n",
      "The ITS Division of Legal Affairs (DLA)  5 The reference answer states that the ITS\n",
      "The ITS Division of Legal Affairs (DLA)  5 The reference answer states that the ITS\n",
      "9 What are examples of ITS E-equipment?\n",
      "Examples of ITS E-equipment include, but 5 The reference answer lists examples of I\n",
      "ITS E-equipment refers to hardware used  5 The reference answer provides a definiti\n",
      "10 What ITS guidelines must be followed when disposing of end of life E-equipment?\n",
      "The ITS (Information Technology Standard 1 The reference answer specifies that the \n",
      "The ITS guidelines that must be followed 5 The reference answer specifies two key g\n",
      "11 What must be submitted once ITS E-equipment is prepared for surplus or disposal?\n",
      "An ITSM ServiceNow Surplus/LDA Service R 5 The reference answer states that an 'ITS\n",
      "An ITSM ServiceNow Surplus/LDA Service R 5 The reference answer states that an 'ITS\n",
      "12 What is the purpose of the Use of Artificial Intelligence policy?\n",
      "The Use of Artificial Intelligence polic 5 The reference answer states that the pur\n",
      "The purpose of the Use of Artificial Int 5 The reference answer states that the pur\n",
      "13 What is the benefit of the Use of Artificial Intelligence policy?\n",
      "The benefit of the Use of Artificial Int 5 The reference answer highlights several \n",
      "The benefit of the Use of Artificial Int 5 The reference answer outlines several ke\n",
      "14 Are the guidelines on the use of Artificial Intelligence a policy or a standard?\n",
      "The guidelines on the use of Artificial  1 The reference answer clearly states that\n",
      "The guidelines on the use of Artificial  5 The reference answer states that the gui\n",
      "15 Who can I email if I have a question about ITS policies and standards for technology use?\n",
      "You can email its.sm.dla@its.ny.gov for  1 The reference answer provides a specific\n",
      "You can email the Chief Data Office at c 1 The reference answer provides a specific\n",
      "16 Where can I find policies, standards, and guidelines for New York State technology policies?\n",
      "The policies, standards, and guidelines  4 The reference answer provides a specific\n",
      "The policies, standards, and guidelines  1 The reference answer provides a URL wher\n",
      "17 What is the telephone number to submit inquiries and requests about ITS policies and standards?\n",
      "The telephone number to submit inquiries 1 The reference answer provides the teleph\n",
      "The telephone number to submit inquiries 1 The reference answer provides the teleph\n",
      "18 What was the change made to the ITS policy on the surplus and disposal of equipment in January 2011?\n",
      "The change made to the ITS policy on the 1 The reference answer indicates that the \n",
      "The change made to the ITS policy on the 2 The reference answer states that the cha\n",
      "19 Who have been the reviewers on changes to the ITS policy for the disposal of equipment?\n",
      "The reviewers on changes to the ITS poli 1 The reference answer identifies 'the CIO\n",
      "The ITS policy for the disposal of equip 2 The reference answer states that the CIO\n",
      "20 When was the policy on the surplus and disposal of ITS equipment first created?\n",
      "The policy on the surplus and disposal o 4 The reference answer provides a specific\n",
      "The policy on the surplus and disposal o 1 The reference answer states that the ori\n",
      "21 What are documents related to the ITS policy on surplus and disposal of equipment?\n",
      "The documents related to the ITS policy  3 The reference answer lists the following\n",
      "The documents related to the ITS policy  5 The reference answer lists the following\n",
      "22 Which forms are related to the ITS policy on surplus and disposal of equipment?\n",
      "The forms related to the ITS policy on s 4 The reference answer lists two specific \n",
      "The forms related to the ITS policy on s 5 The reference answer lists two forms rel\n",
      "23 Are there documents related to the ITS policy on surplus and disposal of equipment?\n",
      "Yes, there are documents related to the  5 The reference answer confirms the existe\n",
      "Yes, there are several related documents 5 The reference answer confirms the existe\n",
      "24 Are some of the State's transformative infrastructure projects financed outside of the State budget?\n",
      "Yes, some of the State's transformative  5 The reference answer states that several\n",
      "Yes, some of the State's transformative  5 The reference answer states that several\n",
      "25 What is the State Share for the Gateway Tunnel Project?\n",
      "The State Share for the Gateway Tunnel P 5 The reference answer provides a single k\n",
      "The State Share for the Gateway Tunnel P 5 The reference answer provides a single k\n",
      "26 Who are the funding partners for the State's transformative infrastructure projects?\n",
      "The funding partners for the State's tra 5 The reference answer lists the funding p\n",
      "The funding partners for the State's tra 5 The reference answer lists the funding p\n",
      "27 What percent of State capital spending in FY 2025 is expected to be supported from Federal aid?\n",
      "The answer is 20 percent. This means tha 2 The reference answer states that 19 perc\n",
      "19 percent of State capital spending in  4 The reference answer provides two key fa\n",
      "28 Is capital spending expected to increase in FY 2025?\n",
      "Yes, capital spending is indeed expected 4 The reference answer states that capital\n",
      "Yes, capital spending is expected to inc 5 The reference answer states that capital\n",
      "29 Why is State capital spending projected to increase in FY 2025?\n",
      "State capital spending is projected to r 4 The reference answer provides two key re\n",
      "State capital spending is projected to i 5 The reference answer provides two key re\n",
      "30 What is capital spending for the State projected in FY 2025?\n",
      "The State's capital spending is projecte 5 The reference answer provides a single k\n",
      "Capital spending for the State is projec 5 The reference answer provides a single k\n",
      "31 What are new large scale projects in the Five-Year DOT capital plan?\n",
      "The Five-Year DOT Capital Plan includes  1 The reference answer lists specific new \n",
      "The new large scale projects in the Five 5 The reference answer lists four key proj\n",
      "32 How much does the DOT Capital plan include for the \"Bridge NY\" program?\n",
      "The DOT Capital Plan includes $1 billion 5 The reference answer provides a single k\n",
      "The DOT Capital Plan includes $1 billion 5 The reference answer states that the DOT\n",
      "33 What percentage of existing State-releated debt is projected to be retired in 15 years?\n",
      "The answer is 15%. This means that, base 1 The reference answer states that 59% of \n",
      "The percentage of existing State-related 5 The reference answer provides a single k\n",
      "34 What does 100% State-releated debt retirement represent?\n",
      "100% State-related debt retirement refer 4 The reference answer states that 100% de\n",
      "100% State-related debt retirement repre 3 The reference answer states that 100% de\n",
      "35 What impact does the rate of debt retirement have on the State?\n",
      "The rate of debt retirement has a signif 4 The reference answer highlights that the\n",
      "The rate at which State-related debt is  5 The reference answer states that the rat\n",
      "36 How much will be appropriated on Community Services Programs for people with development disabilities in FY 2026?\n",
      "The amount appropriated for Community Se 1 The key fact covered in the reference an\n",
      "The answer cannot be determined from the 1 The reference answer provides a specific\n",
      "37 What are the projected appropriations from FY 2025 to FY 2027 for Non-Bondable Projects for people with developmental disabilities?\n",
      "The projected appropriations for Non-Bon 2 The reference answer provides the projec\n",
      "The projected appropriations for Non-Bon 3 The reference answer provides the projec\n",
      "38 What is the total projected appropriation on programs for people with development disabilities in FY 2026?\n",
      "The total projected appropriation on pro 1 The key fact in the reference answer is \n",
      "The total projected appropriation on pro 1 The reference answer provides a specific\n",
      "--------------------------------------------------------------------------------\n",
      "granite_3_0_8b_instruct\n",
      "0 What does an employee need to provide in an appeal to the Telecommuting Appeal board?\n",
      "An employee needs to provide a written r 4 The reference answer specifies that an e\n",
      "1 Who is on the Telecommuting Appeal Board?\n",
      "The Telecommuting Appeal Board consists  5 The reference answer states that the Tel\n",
      "2 How long do employees have to wait until they may submit a new application for the telecommuting program?\n",
      "Employees who have been removed from the 4 The reference answer provides two key fa\n",
      "3 Should SE websites have sub-domain addresses?\n",
      "Based on the provided context, SE websit 4 The reference answer suggests that SE we\n",
      "4 When should SE domain names use acronyms?\n",
      "SE domain names should use acronyms when 4 The reference answer provides two key co\n",
      "5 Can SE domain names contail special characters?\n",
      "No, SE domain names cannot contain speci 4 The reference answer states that SE doma\n",
      "6 Should OSS options be considered first for all potential ITS software solutions?\n",
      "Yes, OSS options should be considered fi 5 The reference answer contains two key fa\n",
      "7 What conditions should OSS meet to be used as an ITS software solution?\n",
      "To be used as an ITS software solution,  5 The reference answer lists four key cond\n",
      "8 Who approves software licenses for ITS?\n",
      "The ITS Division of Legal Affairs (DLA)  5 The reference answer states that the ITS\n",
      "9 What are examples of ITS E-equipment?\n",
      "Based on the provided context, examples  5 The reference answer lists examples of I\n",
      "10 What ITS guidelines must be followed when disposing of end of life E-equipment?\n",
      "The ITS guidelines that must be followed 4 The reference answer provides two key gu\n",
      "11 What must be submitted once ITS E-equipment is prepared for surplus or disposal?\n",
      "Once ITS E-equipment is prepared for sur 5 The reference answer states that an 'ITS\n",
      "12 What is the purpose of the Use of Artificial Intelligence policy?\n",
      "The purpose of the Use of Artificial Int 4 The reference answer states that the pur\n",
      "13 What is the benefit of the Use of Artificial Intelligence policy?\n",
      "The benefit of the Use of Artificial Int 5 The reference answer highlights several \n",
      "14 Are the guidelines on the use of Artificial Intelligence a policy or a standard?\n",
      "The guidelines on the use of Artificial  5 The reference answer states that the gui\n",
      "15 Who can I email if I have a question about ITS policies and standards for technology use?\n",
      "You can email the Chief Data Office at c 1 The reference answer provides an email a\n",
      "16 Where can I find policies, standards, and guidelines for New York State technology policies?\n",
      "You can find policies, standards, and gu 5 The reference answer provides a specific\n",
      "17 What is the telephone number to submit inquiries and requests about ITS policies and standards?\n",
      "The telephone number to submit inquiries 1 The key fact covered in the reference an\n",
      "18 What was the change made to the ITS policy on the surplus and disposal of equipment in January 2011?\n",
      "The context does not provide information 1 The reference answer indicates that a re\n",
      "19 Who have been the reviewers on changes to the ITS policy for the disposal of equipment?\n",
      "The reviewers for changes to the ITS pol 2 The reference answer specifies that the \n",
      "20 When was the policy on the surplus and disposal of ITS equipment first created?\n",
      "The policy on the surplus and disposal o 1 The key fact in the reference answer is \n",
      "21 What are documents related to the ITS policy on surplus and disposal of equipment?\n",
      "The related documents to the ITS policy  5 The reference answer lists five document\n",
      "22 Which forms are related to the ITS policy on surplus and disposal of equipment?\n",
      "The forms related to the ITS policy on s 5 The reference answer lists two forms rel\n",
      "23 Are there documents related to the ITS policy on surplus and disposal of equipment?\n",
      "Yes, there are related documents to the  5 The reference answer confirms the existe\n",
      "24 Are some of the State's transformative infrastructure projects financed outside of the State budget?\n",
      "Yes, some of the State's transformative  5 The reference answer states that several\n",
      "25 What is the State Share for the Gateway Tunnel Project?\n",
      "The State Share for the Gateway Tunnel P 5 The reference answer states that the Sta\n",
      "26 Who are the funding partners for the State's transformative infrastructure projects?\n",
      "The funding partners for the State's tra 5 The reference answer lists the funding p\n",
      "27 What percent of State capital spending in FY 2025 is expected to be supported from Federal aid?\n",
      "19 percent of State capital spending in  4 The reference answer provides two key fa\n",
      "28 Is capital spending expected to increase in FY 2025?\n",
      "Yes, capital spending is expected to inc 5 The reference answer states that capital\n",
      "29 Why is State capital spending projected to increase in FY 2025?\n",
      "State capital spending is projected to i 5 The reference answer provides two key re\n",
      "30 What is capital spending for the State projected in FY 2025?\n",
      "Capital spending for the State is projec 5 The reference answer provides a single k\n",
      "31 What are new large scale projects in the Five-Year DOT capital plan?\n",
      "The new large-scale projects in the Five 5 The reference answer lists four key proj\n",
      "32 How much does the DOT Capital plan include for the \"Bridge NY\" program?\n",
      "The DOT Capital Plan includes $1 billion 5 The reference answer states that the DOT\n",
      "33 What percentage of existing State-releated debt is projected to be retired in 15 years?\n",
      "The percentage of existing State-related 5 The reference answer states that 59% of \n",
      "34 What does 100% State-releated debt retirement represent?\n",
      "100% State-related debt retirement would 2 The reference answer defines 100% State-\n",
      "35 What impact does the rate of debt retirement have on the State?\n",
      "The rate of debt retirement has a signif 4 The reference answer highlights the impa\n",
      "36 How much will be appropriated on Community Services Programs for people with development disabilities in FY 2026?\n",
      "The context provided does not include sp 1 The reference answer provides a specific\n",
      "37 What are the projected appropriations from FY 2025 to FY 2027 for Non-Bondable Projects for people with developmental disabilities?\n",
      "The context provided does not include sp 1 The reference answer provides specific f\n",
      "38 What is the total projected appropriation on programs for people with development disabilities in FY 2026?\n",
      "The total projected appropriation on pro 1 The reference answer provides the total \n"
     ]
    }
   ],
   "source": [
    "for testing_config in llm_config[\"testing_config\"]:\n",
    "    testing_config_name = replace_special_char(testing_config[\"name\" or \"model_name\"])\n",
    "    print(\"-\" * 80)\n",
    "    print(testing_config_name)\n",
    "    answers_filename = f\"{output_directory}/{testing_config_name}_answers.jsonl\"\n",
    "    scores = pd.read_json(answers_filename, orient=\"records\", lines=True)\n",
    "    position = scores.columns.get_loc(\"answer\")\n",
    "    scores.insert(position + 1, \"answer_score\", \"\")\n",
    "    scores.insert(position + 2, \"answer_score_reasoning\", \"\")\n",
    "    position = scores.columns.get_loc(\"rag_answer\")\n",
    "    scores.insert(position + 1, \"rag_answer_score\", \"\")\n",
    "    scores.insert(position + 2, \"rag_answer_score_reasoning\", \"\")\n",
    "\n",
    "    for index, row in scores.iterrows():\n",
    "        question = row[\"question\"]\n",
    "        answer = row[\"answer\"]\n",
    "        reference_answer = row[\"ground_truth\"]\n",
    "        print(index, question)\n",
    "        if answer:\n",
    "            score, reasoning = score_request(question, answer, reference_answer)\n",
    "            scores.at[index, \"answer_score\"] = score\n",
    "            scores.at[index, \"answer_score_reasoning\"] = reasoning\n",
    "            print(answer[:40], score, reasoning[:40])\n",
    "        rag_answer = row[\"rag_answer\"]\n",
    "        if rag_answer:\n",
    "            score, reasoning = score_request(question, rag_answer, reference_answer)\n",
    "            scores.at[index, \"rag_answer_score\"] = score\n",
    "            scores.at[index, \"rag_answer_score_reasoning\"] = reasoning\n",
    "            print(rag_answer[:40], score, reasoning[:40])\n",
    "    judge_name = replace_special_char(judge_model_name)\n",
    "    scores_filename = f\"{output_directory}/{testing_config_name}_scores\"\n",
    "    scores.to_json(f\"{scores_filename}.jsonl\", orient=\"records\", lines=True)\n",
    "    scores.to_csv(f\"{scores_filename}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c9ad25-b957-4fab-aea9-b9b828e030d2",
   "metadata": {},
   "source": [
    "## Create resulting score report CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bd1cedae-4bbf-419d-87cb-d5aedf404694",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T18:25:16.967516Z",
     "start_time": "2024-11-11T18:25:16.949360Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetuned_answer_score                      3.128205\n",
      "finetuned_rag_answer_score                  3.974359\n",
      "granite_3_0_8b_instruct_rag_answer_score    3.897436\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "with open(\"llm_config.yaml\", \"r\") as f:\n",
    "    llm_config = yaml.safe_load(f)\n",
    "\n",
    "output_directory = llm_config.get(\"name\", \"output\")\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "judge_client = OpenAI(api_key=llm_config[\"judge\"][\"api_key\"])\n",
    "judge_model_name = llm_config[\"judge\"][\"model_name\"]\n",
    "judge_name = replace_special_char(judge_model_name)\n",
    "\n",
    "summary_output_df = pd.DataFrame()\n",
    "\n",
    "for testing_config in llm_config[\"testing_config\"]:\n",
    "    testing_config_name = replace_special_char(testing_config[\"name\" or \"model_name\"])\n",
    "    scores_filename = f\"{output_directory}/{testing_config_name}_scores.jsonl\"\n",
    "    scores = pd.read_json(scores_filename, orient=\"records\", lines=True)\n",
    "    if testing_config.get(\"qna_template\"):\n",
    "        summary_output_df[f\"{testing_config_name}_answer_score\"] = scores[\"answer_score\"]\n",
    "    if testing_config.get(\"rag_template\"):\n",
    "        summary_output_df[f\"{testing_config_name}_rag_answer_score\"] = scores[\"rag_answer_score\"]\n",
    "\n",
    "average_row = summary_output_df.mean(axis=0, numeric_only=True)\n",
    "print(average_row)\n",
    "summary_output_df.loc[len(summary_output_df)] = average_row\n",
    "question_indices = [f\"Q{i+1}\" for i in range(len(summary_output_df)-1)]\n",
    "question_indices.append(\"Average\")\n",
    "summary_output_df.insert(0, 'question index', question_indices)\n",
    "\n",
    "summary_filepath = f\"{output_directory}/summary_scores\"\n",
    "# summary_output_df.to_json(f\"{summary_filepath}.jsonl\", orient=\"records\", lines=True)\n",
    "summary_output_df.to_csv(f\"{summary_filepath}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "785bb2e5bde823e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(f\"{output_directory}/{judge_name}_scores.xlsx\") as writer:\n",
    "    summary_output_df = pd.read_csv(f\"{summary_filepath}.csv\")\n",
    "    summary_output_df.to_excel(writer, sheet_name=\"Summary\", index=False)\n",
    "\n",
    "    for testing_config in llm_config[\"testing_config\"]:\n",
    "        testing_config_name = replace_special_char(testing_config[\"name\" or \"model_name\"])\n",
    "        scores_filename = f\"{output_directory}/{testing_config_name}_scores.jsonl\"\n",
    "        scores = pd.read_json(scores_filename, orient=\"records\", lines=True)\n",
    "        scores.to_excel(writer, sheet_name=f\"{testing_config_name}_scores\"[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2192c3-477f-4fa3-ae04-4222e8a4d979",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
